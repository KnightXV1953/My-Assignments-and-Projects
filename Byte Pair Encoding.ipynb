{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "import re\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"dataset\"  \n",
    "content_list = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):  \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "            content = file.read()\n",
    "            content_list.append(content)  \n",
    "content_string = \" \".join(content_list) \n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r\"^\\d+\\.\\s*\", \"\", text, flags=re.MULTILINE)  # to remove the numbers from start of sentences\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip() \n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique characters\n",
    "def unique_characters(processedtext):\n",
    "    unique_chars = sorted(set(processedtext))\n",
    "    character_to_id = {\"<UNK>\": 0} # assign unknown to 0\n",
    "    index = 1\n",
    "    for i in unique_chars:\n",
    "        character_to_id[i] = index\n",
    "        index+=1\n",
    "    return character_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    tokenized_words = []  \n",
    "    for word in words:\n",
    "        tokenized_word = list(word)  \n",
    "        tokenized_word.append('_')  \n",
    "        tokenized_words.append(tokenized_word)  \n",
    "    return tokenized_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of pairs\n",
    "def get_frequency(corpus):\n",
    "    pairs = defaultdict(int) # make a empty dict\n",
    "    for word in corpus:\n",
    "        for i in range(len(word) - 1):\n",
    "            pairs[(word[i], word[i + 1])] += 1\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the most frequent pair\n",
    "def merge_pair(pair, corpus):\n",
    "    new_token = \"\".join(pair)\n",
    "    new_corpus = []\n",
    "    for word in corpus:\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            if i < len(word) - 1 and (word[i], word[i + 1]) == pair:\n",
    "                new_word.append(new_token)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_corpus.append(new_word)\n",
    "    return new_corpus, new_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_pair_encoding(corpus , vocab_size = 1000):\n",
    "    vocab = set()\n",
    "    for i in corpus:\n",
    "        for j in i:\n",
    "            vocab.add(j)\n",
    "\n",
    "    while len(vocab) <= vocab_size:\n",
    "        pair_freq = get_frequency(corpus)\n",
    "        if not pair_freq:\n",
    "            break\n",
    "        most_frequent_pair = max(pair_freq , key = pair_freq.get)\n",
    "        corpus, new_token = merge_pair(most_frequent_pair, corpus)\n",
    "        vocab.add(new_token)\n",
    "        print(f\"Merged pair {most_frequent_pair} into token '{new_token}' with frequency {pair_freq[most_frequent_pair]}\")\n",
    "    return vocab, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, vocab_ids):\n",
    "    tokens = []\n",
    "    text = text.replace(\" \", \"_\")  \n",
    "\n",
    "    # Sort vocabulary keys by length (longest first)\n",
    "    sorted_vocab = sorted(vocab_ids.keys(), key=len, reverse=True)\n",
    "    print(sorted_vocab)\n",
    "\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        matched = False\n",
    "        \n",
    "        for v in sorted_vocab:  # Iterate over sorted vocab and find the longest match\n",
    "            if text.startswith(v, i):  # Check if a substring of the text matches a vocab token\n",
    "                tokens.append(vocab_ids[v])  # Use vocab_ids[v] to get the ID\n",
    "                i += len(v)  # Move index by the length of the matched token\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        if not matched:\n",
    "            tokens.append(0)  # Append <UNK> ID (0)\n",
    "            i += 1  # Move forward by one character\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(token_ids, vocab_ids):\n",
    "    # Create a reverse mapping from ID to word\n",
    "    id_to_word = {v: k for k, v in vocab_ids.items()}\n",
    "\n",
    "    text = \"\".join(id_to_word[token] for token in token_ids if token in id_to_word)\n",
    "    \n",
    "    return text.replace(\"_\", \" \")  # Replace underscores with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character to ID Mapping: {'<UNK>': 0, ' ': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, '_': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'k': 23, 'l': 24, 'm': 25, 'n': 26, 'o': 27, 'p': 28, 'q': 29, 'r': 30, 's': 31, 't': 32, 'u': 33, 'v': 34, 'w': 35, 'x': 36, 'y': 37, 'z': 38, 'Ã©': 39}\n",
      "Initial Corpus: [['s', 'u', 'b', 'h', 'a', '_'], ['5', '_'], ['b', 'j', 'h', 'e', 'y', '_'], ['u', 't', 'h', 'n', 'a', '_'], ['p', 'e', 'r', 'h', 'a', '_']]\n"
     ]
    }
   ],
   "source": [
    "processedtext = preprocess_text(content_string)\n",
    "character_mapping = unique_characters(processedtext)\n",
    "\n",
    "print(\"Character to ID Mapping:\", character_mapping)\n",
    "\n",
    "corpus = tokenize_text(processedtext)\n",
    "print(\"Initial Corpus:\", corpus[:5])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged pair ('a', '_') into token 'a_' with frequency 2790\n",
      "Merged pair ('e', '_') into token 'e_' with frequency 2239\n",
      "Merged pair ('i', '_') into token 'i_' with frequency 2142\n",
      "Merged pair ('r', '_') into token 'r_' with frequency 1989\n",
      "Merged pair ('a', 'y') into token 'ay' with frequency 1198\n",
      "Merged pair ('h', 'a') into token 'ha' with frequency 990\n",
      "Merged pair ('n', '_') into token 'n_' with frequency 856\n",
      "Merged pair ('t', 'h') into token 'th' with frequency 843\n",
      "Merged pair ('a', 'a') into token 'aa' with frequency 828\n",
      "Merged pair ('ay', '_') into token 'ay_' with frequency 585\n",
      "Merged pair ('s', '_') into token 's_' with frequency 575\n",
      "Merged pair ('k', 'a') into token 'ka' with frequency 555\n",
      "Merged pair ('m', 'a') into token 'ma' with frequency 508\n",
      "Merged pair ('o', '_') into token 'o_' with frequency 495\n",
      "Merged pair ('a', 'u') into token 'au' with frequency 490\n",
      "Merged pair ('h', '_') into token 'h_' with frequency 490\n",
      "Merged pair ('k', '_') into token 'k_' with frequency 487\n",
      "Merged pair ('au', 'r_') into token 'aur_' with frequency 472\n",
      "Merged pair ('y', '_') into token 'y_' with frequency 466\n",
      "Merged pair ('b', 'a') into token 'ba' with frequency 466\n",
      "Merged pair ('i', 'n_') into token 'in_' with frequency 462\n",
      "Merged pair ('i', 'y') into token 'iy' with frequency 456\n",
      "Merged pair ('d', '_') into token 'd_' with frequency 447\n",
      "Merged pair ('t', '_') into token 't_' with frequency 444\n",
      "Merged pair ('m', 'e') into token 'me' with frequency 433\n",
      "Merged pair ('k', 'i_') into token 'ki_' with frequency 424\n",
      "Merged pair ('k', 'e_') into token 'ke_' with frequency 419\n",
      "Merged pair ('i', 'r_') into token 'ir_' with frequency 417\n",
      "Merged pair ('l', 'a') into token 'la' with frequency 398\n",
      "Merged pair ('n', 'e_') into token 'ne_' with frequency 394\n",
      "Merged pair ('p', 'h') into token 'ph' with frequency 389\n",
      "Merged pair ('h', 'i_') into token 'hi_' with frequency 369\n",
      "Merged pair ('ay', 'a_') into token 'aya_' with frequency 367\n",
      "Merged pair ('m', '_') into token 'm_' with frequency 365\n",
      "Merged pair ('n', 'a') into token 'na' with frequency 333\n",
      "Merged pair ('ph', 'ir_') into token 'phir_' with frequency 324\n",
      "Merged pair ('a', 'r') into token 'ar' with frequency 311\n",
      "Merged pair ('l', '_') into token 'l_' with frequency 299\n",
      "Merged pair ('w', 'a') into token 'wa' with frequency 283\n",
      "Merged pair ('s', 'a') into token 'sa' with frequency 282\n",
      "Merged pair ('b', 'aa') into token 'baa' with frequency 280\n",
      "Merged pair ('s', 'e_') into token 'se_' with frequency 273\n",
      "Merged pair ('h', 'u') into token 'hu' with frequency 272\n",
      "Merged pair ('h', 'a_') into token 'ha_' with frequency 271\n",
      "Merged pair ('k', 'a_') into token 'ka_' with frequency 271\n",
      "Merged pair ('n', 'a_') into token 'na_' with frequency 261\n",
      "Merged pair ('h', 'o') into token 'ho' with frequency 254\n",
      "Merged pair ('th', 'a_') into token 'tha_' with frequency 249\n",
      "Merged pair ('iy', 'a_') into token 'iya_' with frequency 246\n",
      "Merged pair ('u', 'n') into token 'un' with frequency 242\n",
      "Merged pair ('o', 'r_') into token 'or_' with frequency 230\n",
      "Merged pair ('s', 'i') into token 'si' with frequency 226\n",
      "Merged pair ('th', '_') into token 'th_' with frequency 223\n",
      "Merged pair ('baa', 'd_') into token 'baad_' with frequency 221\n",
      "Merged pair ('r', 'e') into token 're' with frequency 218\n",
      "Merged pair ('r', 'a') into token 'ra' with frequency 211\n",
      "Merged pair ('g', 'aya_') into token 'gaya_' with frequency 201\n",
      "Merged pair ('c', 'h_') into token 'ch_' with frequency 193\n",
      "Merged pair ('e', 'r') into token 'er' with frequency 191\n",
      "Merged pair ('s', 't') into token 'st' with frequency 191\n",
      "Merged pair ('ha', 'r_') into token 'har_' with frequency 189\n",
      "Merged pair ('d', 'e') into token 'de' with frequency 187\n",
      "Merged pair ('me', 'in_') into token 'mein_' with frequency 185\n",
      "Merged pair ('k', 'ha') into token 'kha' with frequency 182\n",
      "Merged pair ('0', '_') into token '0_' with frequency 181\n",
      "Merged pair ('t', 'a') into token 'ta' with frequency 179\n",
      "Merged pair ('iy', 'e_') into token 'iye_' with frequency 179\n",
      "Merged pair ('j', '_') into token 'j_' with frequency 179\n",
      "Merged pair ('k', 'iya_') into token 'kiya_' with frequency 178\n",
      "Merged pair ('c', 'ha') into token 'cha' with frequency 172\n",
      "Merged pair ('ba', 'j') into token 'baj' with frequency 170\n",
      "Merged pair ('i', 'n') into token 'in' with frequency 167\n",
      "Merged pair ('ka', 'r_') into token 'kar_' with frequency 165\n",
      "Merged pair ('l', 'e') into token 'le' with frequency 163\n",
      "Merged pair ('th', 'o') into token 'tho' with frequency 162\n",
      "Merged pair ('k', 'h') into token 'kh' with frequency 158\n",
      "Merged pair ('g', 'har_') into token 'ghar_' with frequency 153\n",
      "Merged pair ('z', '_') into token 'z_' with frequency 151\n",
      "Merged pair ('i', 'v') into token 'iv' with frequency 150\n",
      "Merged pair ('d', 'o') into token 'do' with frequency 150\n",
      "Merged pair ('t', 'y_') into token 'ty_' with frequency 149\n",
      "Merged pair ('b', '_') into token 'b_' with frequency 149\n",
      "Merged pair ('p', 'a') into token 'pa' with frequency 148\n",
      "Merged pair ('t', 'a_') into token 'ta_' with frequency 146\n",
      "Merged pair ('o', 'n_') into token 'on_' with frequency 144\n",
      "Merged pair ('p', '_') into token 'p_' with frequency 140\n",
      "Merged pair ('s', 'u') into token 'su' with frequency 139\n",
      "Merged pair ('l', 'iye_') into token 'liye_' with frequency 139\n",
      "Merged pair ('c', 'la') into token 'cla' with frequency 138\n",
      "Merged pair ('cla', 's') into token 'clas' with frequency 138\n",
      "Merged pair ('m', 'e_') into token 'me_' with frequency 137\n",
      "Merged pair ('k', 'aa') into token 'kaa' with frequency 136\n",
      "Merged pair ('g', 'a') into token 'ga' with frequency 133\n",
      "Merged pair ('un', 'iv') into token 'univ' with frequency 132\n",
      "Merged pair ('univ', 'er') into token 'univer' with frequency 132\n",
      "Merged pair ('s', 'o') into token 'so' with frequency 130\n",
      "Merged pair ('s', 'h') into token 'sh' with frequency 130\n",
      "Merged pair ('r', 'o') into token 'ro' with frequency 130\n",
      "Merged pair ('j', 'a') into token 'ja' with frequency 129\n",
      "Merged pair ('y', 'a_') into token 'ya_' with frequency 129\n",
      "Merged pair ('univer', 'si') into token 'universi' with frequency 129\n",
      "Merged pair ('universi', 'ty_') into token 'university_' with frequency 128\n",
      "Merged pair ('g', 'ay') into token 'gay' with frequency 128\n",
      "Merged pair ('e', 'e') into token 'ee' with frequency 126\n",
      "Merged pair ('n', 'ay_') into token 'nay_' with frequency 126\n",
      "Merged pair ('k', 'o_') into token 'ko_' with frequency 126\n",
      "Merged pair ('1', '_') into token '1_' with frequency 125\n",
      "Merged pair ('ka', 'r') into token 'kar' with frequency 125\n",
      "Merged pair ('r', 'i_') into token 'ri_' with frequency 122\n",
      "Merged pair ('l', 'a_') into token 'la_' with frequency 121\n",
      "Merged pair ('u', 's') into token 'us' with frequency 121\n",
      "Merged pair ('b', 'hi_') into token 'bhi_' with frequency 119\n",
      "Merged pair ('e', 'r_') into token 'er_' with frequency 117\n",
      "Merged pair ('th', 'i_') into token 'thi_' with frequency 117\n",
      "Merged pair ('p', 'ar') into token 'par' with frequency 117\n",
      "Merged pair ('a', 'p') into token 'ap' with frequency 112\n",
      "Merged pair ('d', 'i_') into token 'di_' with frequency 110\n",
      "Merged pair ('i', 's') into token 'is' with frequency 110\n",
      "Merged pair ('g', '_') into token 'g_' with frequency 108\n",
      "Merged pair ('i', 'a_') into token 'ia_' with frequency 108\n",
      "Merged pair ('k', 'u') into token 'ku' with frequency 107\n",
      "Merged pair ('p', 'o') into token 'po' with frequency 103\n",
      "Merged pair ('sa', 'th_') into token 'sath_' with frequency 103\n",
      "Merged pair ('t', 'i') into token 'ti' with frequency 102\n",
      "Merged pair ('t', 'o') into token 'to' with frequency 102\n",
      "Merged pair ('r', 'a_') into token 'ra_' with frequency 100\n",
      "Merged pair ('t', 'e_') into token 'te_' with frequency 100\n",
      "Merged pair ('l', 'i_') into token 'li_' with frequency 96\n",
      "Merged pair ('kaa', 'm_') into token 'kaam_' with frequency 94\n",
      "Merged pair ('na', 'sh') into token 'nash' with frequency 92\n",
      "Merged pair ('l', 'e_') into token 'le_' with frequency 92\n",
      "Merged pair ('n', 'd_') into token 'nd_' with frequency 92\n",
      "Merged pair ('h', 'o_') into token 'ho_' with frequency 92\n",
      "Merged pair ('ha', 'i_') into token 'hai_' with frequency 91\n",
      "Merged pair ('clas', 's_') into token 'class_' with frequency 90\n",
      "Merged pair ('aa', 'j_') into token 'aaj_' with frequency 90\n",
      "Merged pair ('ku', 'ch_') into token 'kuch_' with frequency 90\n",
      "Merged pair ('c', 'h') into token 'ch' with frequency 89\n",
      "Merged pair ('d', 'a_') into token 'da_' with frequency 89\n",
      "Merged pair ('u', '_') into token 'u_' with frequency 87\n",
      "Merged pair ('d', 'a') into token 'da' with frequency 87\n",
      "Merged pair ('na', 'ma') into token 'nama' with frequency 87\n",
      "Merged pair ('nama', 'z_') into token 'namaz_' with frequency 86\n",
      "Merged pair ('t', 'e') into token 'te' with frequency 86\n",
      "Merged pair ('m', 'i') into token 'mi' with frequency 85\n",
      "Merged pair ('kha', 'na_') into token 'khana_' with frequency 85\n",
      "Merged pair ('s', 'e') into token 'se' with frequency 84\n",
      "Merged pair ('i', 's_') into token 'is_' with frequency 83\n",
      "Merged pair ('ma', 'i_') into token 'mai_' with frequency 83\n",
      "Merged pair ('ta', 'k_') into token 'tak_' with frequency 82\n",
      "Merged pair ('baj', 'e_') into token 'baje_' with frequency 81\n",
      "Merged pair ('baj', 'ay_') into token 'bajay_' with frequency 79\n",
      "Merged pair ('k', 'ia_') into token 'kia_' with frequency 79\n",
      "Merged pair ('3', '0_') into token '30_' with frequency 79\n",
      "Merged pair ('nash', 'ta_') into token 'nashta_' with frequency 78\n",
      "Merged pair ('u', 's_') into token 'us_' with frequency 76\n",
      "Merged pair ('t', 'o_') into token 'to_' with frequency 76\n",
      "Merged pair ('k', 'ay_') into token 'kay_' with frequency 74\n",
      "Merged pair ('s', 't_') into token 'st_' with frequency 72\n",
      "Merged pair ('k', 'r_') into token 'kr_' with frequency 72\n",
      "Merged pair ('p', 'e') into token 'pe' with frequency 71\n",
      "Merged pair ('a', 'r_') into token 'ar_' with frequency 71\n",
      "Merged pair ('ma', 'in_') into token 'main_' with frequency 69\n",
      "Merged pair ('kh', 'aya_') into token 'khaya_' with frequency 69\n",
      "Merged pair ('m', 'a_') into token 'ma_' with frequency 69\n",
      "Merged pair ('a', 'j_') into token 'aj_' with frequency 68\n",
      "Merged pair ('g', 'ya_') into token 'gya_' with frequency 68\n",
      "Merged pair ('gay', 'i_') into token 'gayi_' with frequency 68\n",
      "Merged pair ('l', 'i') into token 'li' with frequency 67\n",
      "Merged pair ('n', 'y_') into token 'ny_' with frequency 67\n",
      "Merged pair ('b', 'e') into token 'be' with frequency 66\n",
      "Merged pair ('m', 'u') into token 'mu' with frequency 65\n",
      "Merged pair ('in', 'g_') into token 'ing_' with frequency 65\n",
      "Merged pair ('t', 'u') into token 'tu' with frequency 64\n",
      "Merged pair ('c', 'a') into token 'ca' with frequency 64\n",
      "Merged pair ('cha', 'la_') into token 'chala_' with frequency 63\n",
      "Merged pair ('su', 'b') into token 'sub' with frequency 62\n",
      "Merged pair ('r', 'e_') into token 're_' with frequency 62\n",
      "Merged pair ('n', 'i_') into token 'ni_' with frequency 62\n",
      "Merged pair ('s', 'aa') into token 'saa' with frequency 62\n",
      "Merged pair ('k', 'e') into token 'ke' with frequency 61\n",
      "Merged pair ('r', 'aa') into token 'raa' with frequency 61\n",
      "Merged pair ('c', 'o') into token 'co' with frequency 60\n",
      "Merged pair ('b', 'o') into token 'bo' with frequency 60\n",
      "Merged pair ('do', 'st') into token 'dost' with frequency 59\n",
      "Merged pair ('n', 'i') into token 'ni' with frequency 57\n",
      "Merged pair ('ka', 'l_') into token 'kal_' with frequency 57\n",
      "Merged pair ('raa', 't_') into token 'raat_' with frequency 56\n",
      "Merged pair ('h', 'e_') into token 'he_' with frequency 55\n",
      "Merged pair ('s', 'o_') into token 'so_' with frequency 55\n",
      "Merged pair ('hu', 'm_') into token 'hum_' with frequency 54\n",
      "Merged pair ('u', 'tha_') into token 'utha_' with frequency 54\n",
      "Merged pair ('gay', 'e_') into token 'gaye_' with frequency 54\n",
      "Merged pair ('m', 'o') into token 'mo' with frequency 54\n",
      "Merged pair ('d', 'in_') into token 'din_' with frequency 54\n",
      "Merged pair ('f', 're') into token 'fre' with frequency 53\n",
      "Merged pair ('k', 'in_') into token 'kin_' with frequency 53\n",
      "Merged pair ('d', 'i') into token 'di' with frequency 52\n",
      "Merged pair ('c', 'ha_') into token 'cha_' with frequency 52\n",
      "Merged pair ('wa', 'p') into token 'wap' with frequency 51\n",
      "Merged pair ('n', 'e') into token 'ne' with frequency 51\n",
      "Merged pair ('0', '0_') into token '00_' with frequency 51\n",
      "Merged pair ('a', 's') into token 'as' with frequency 51\n",
      "Merged pair ('tho', 'ri_') into token 'thori_' with frequency 50\n",
      "Merged pair ('de', 'r_') into token 'der_' with frequency 50\n",
      "Merged pair ('ha', 'n') into token 'han' with frequency 50\n",
      "Merged pair ('ra', 'ha_') into token 'raha_' with frequency 50\n",
      "Merged pair ('q', 'u') into token 'qu' with frequency 50\n",
      "Merged pair ('de', 'k') into token 'dek' with frequency 50\n",
      "Merged pair ('ti', 'me_') into token 'time_' with frequency 49\n",
      "Merged pair ('k', 'r') into token 'kr' with frequency 49\n",
      "Merged pair ('b', 'i') into token 'bi' with frequency 49\n",
      "Merged pair ('l', 'l_') into token 'll_' with frequency 48\n",
      "Merged pair ('clas', 'se') into token 'classe' with frequency 48\n",
      "Merged pair ('classe', 's_') into token 'classes_' with frequency 48\n",
      "Merged pair ('f', 'i_') into token 'fi_' with frequency 47\n",
      "Merged pair ('n', 't_') into token 'nt_' with frequency 47\n",
      "Merged pair ('do', 'st_') into token 'dost_' with frequency 47\n",
      "Merged pair ('na', 'hi_') into token 'nahi_' with frequency 47\n",
      "Merged pair ('t', 'ay_') into token 'tay_' with frequency 46\n",
      "Merged pair ('a', 'a_') into token 'aa_' with frequency 46\n",
      "Merged pair ('su', 'ba') into token 'suba' with frequency 46\n",
      "Merged pair ('suba', 'h_') into token 'subah_' with frequency 46\n",
      "Merged pair ('s', 'ha') into token 'sha' with frequency 46\n",
      "Merged pair ('s', 'hu') into token 'shu' with frequency 46\n",
      "Merged pair ('r', 'i') into token 'ri' with frequency 45\n",
      "Merged pair ('l', 'di_') into token 'ldi_' with frequency 45\n",
      "Merged pair ('pe', 'h') into token 'peh' with frequency 45\n",
      "Merged pair ('f', 'a') into token 'fa' with frequency 45\n",
      "Merged pair ('pa', 'r_') into token 'par_' with frequency 45\n",
      "Merged pair ('wa', 'l') into token 'wal' with frequency 45\n",
      "Merged pair ('ja', 'ldi_') into token 'jaldi_' with frequency 44\n",
      "Merged pair ('le', 'kin_') into token 'lekin_' with frequency 44\n",
      "Merged pair ('us', 'ke_') into token 'uske_' with frequency 44\n",
      "Merged pair ('par', 'hi_') into token 'parhi_' with frequency 44\n",
      "Merged pair ('ga', 'i_') into token 'gai_' with frequency 44\n",
      "Merged pair ('tho', 'di_') into token 'thodi_' with frequency 44\n",
      "Merged pair ('wap', 'is_') into token 'wapis_' with frequency 43\n",
      "Merged pair ('p', 'er_') into token 'per_' with frequency 43\n",
      "Merged pair ('ka', 'i_') into token 'kai_' with frequency 43\n",
      "Merged pair ('sub', 'ha_') into token 'subha_' with frequency 42\n",
      "Merged pair ('5', '_') into token '5_' with frequency 42\n",
      "Merged pair ('2', '_') into token '2_' with frequency 42\n",
      "Merged pair ('t', 'i_') into token 'ti_' with frequency 42\n",
      "Merged pair ('g', 'a_') into token 'ga_' with frequency 41\n",
      "Merged pair ('g', 'u') into token 'gu' with frequency 41\n",
      "Merged pair ('si', 'g') into token 'sig' with frequency 41\n",
      "Merged pair ('g', 'h') into token 'gh' with frequency 40\n",
      "Merged pair ('dost', 'on_') into token 'doston_' with frequency 40\n",
      "Merged pair ('qu', 'i') into token 'qui' with frequency 40\n",
      "Merged pair ('a', 'm_') into token 'am_' with frequency 40\n",
      "Merged pair ('l', 'y_') into token 'ly_' with frequency 39\n",
      "Merged pair ('v', 'i') into token 'vi' with frequency 39\n",
      "Merged pair ('p', 'ro') into token 'pro' with frequency 39\n",
      "Merged pair ('d', 'u') into token 'du' with frequency 38\n",
      "Merged pair ('le', 'c') into token 'lec' with frequency 38\n",
      "Merged pair ('ay', 'e_') into token 'aye_' with frequency 38\n",
      "Merged pair ('sa', 'b_') into token 'sab_' with frequency 38\n",
      "Merged pair ('k', 'y_') into token 'ky_' with frequency 38\n",
      "Merged pair ('mu', 'j') into token 'muj' with frequency 37\n",
      "Merged pair ('j', 'o_') into token 'jo_' with frequency 37\n",
      "Merged pair ('saa', 'th_') into token 'saath_' with frequency 37\n",
      "Merged pair ('e', 'c') into token 'ec' with frequency 37\n",
      "Merged pair ('ha', 'n_') into token 'han_' with frequency 36\n",
      "Merged pair ('as', 'sig') into token 'assig' with frequency 36\n",
      "Merged pair ('n', 'me') into token 'nme' with frequency 36\n",
      "Merged pair ('t', 's_') into token 'ts_' with frequency 36\n",
      "Merged pair ('b', 'j') into token 'bj' with frequency 35\n",
      "Merged pair ('t', 'y') into token 'ty' with frequency 35\n",
      "Merged pair ('f', '_') into token 'f_' with frequency 35\n",
      "Merged pair ('r', 'ay_') into token 'ray_' with frequency 35\n",
      "Merged pair ('t', 'ay') into token 'tay' with frequency 35\n",
      "Merged pair ('s', 'c') into token 'sc' with frequency 35\n",
      "Merged pair ('assig', 'nme') into token 'assignme' with frequency 35\n",
      "Merged pair ('e', 'k_') into token 'ek_' with frequency 35\n",
      "Merged pair ('to', 'h_') into token 'toh_' with frequency 35\n",
      "Merged pair ('a', 'i') into token 'ai' with frequency 34\n",
      "Merged pair ('ap', 'ne_') into token 'apne_' with frequency 34\n",
      "Merged pair ('lec', 'tu') into token 'lectu' with frequency 34\n",
      "Merged pair ('c', '_') into token 'c_' with frequency 34\n",
      "Merged pair ('qui', 'z_') into token 'quiz_' with frequency 34\n",
      "Merged pair ('i', 'ne_') into token 'ine_' with frequency 34\n",
      "Merged pair ('l', 'ay_') into token 'lay_' with frequency 34\n",
      "Merged pair ('tho', 'da_') into token 'thoda_' with frequency 34\n",
      "Merged pair ('b', 'us_') into token 'bus_' with frequency 33\n",
      "Merged pair ('f', 'i') into token 'fi' with frequency 33\n",
      "Merged pair ('s', 'h_') into token 'sh_' with frequency 33\n",
      "Merged pair ('kaa', 'fi_') into token 'kaafi_' with frequency 33\n",
      "Merged pair ('a', 'n') into token 'an' with frequency 33\n",
      "Merged pair ('c', 'i') into token 'ci' with frequency 33\n",
      "Merged pair ('da', 'ir_') into token 'dair_' with frequency 33\n",
      "Merged pair ('ap', 'ni_') into token 'apni_' with frequency 33\n",
      "Merged pair ('k', 'o') into token 'ko' with frequency 33\n",
      "Merged pair ('p', 'e_') into token 'pe_' with frequency 32\n",
      "Merged pair ('1', '0_') into token '10_' with frequency 32\n",
      "Merged pair ('ro', 'o') into token 'roo' with frequency 32\n",
      "Merged pair ('me', 'i_') into token 'mei_' with frequency 32\n",
      "Merged pair ('st', 'e') into token 'ste' with frequency 32\n",
      "Merged pair ('hu', 'a_') into token 'hua_' with frequency 31\n",
      "Merged pair ('l', 'o') into token 'lo' with frequency 31\n",
      "Merged pair ('u', 'th_') into token 'uth_' with frequency 31\n",
      "Merged pair ('ar', 'i_') into token 'ari_' with frequency 31\n",
      "Merged pair ('k', 'iye_') into token 'kiye_' with frequency 31\n",
      "Merged pair ('l', 'iya_') into token 'liya_' with frequency 31\n",
      "Merged pair ('kar', 'ne_') into token 'karne_' with frequency 31\n",
      "Merged pair ('ra', 'hi_') into token 'rahi_' with frequency 31\n",
      "Merged pair ('t', 'ha') into token 'tha' with frequency 30\n",
      "Merged pair ('ph', 'o') into token 'pho' with frequency 30\n",
      "Merged pair ('ai', 'k_') into token 'aik_' with frequency 30\n",
      "Merged pair ('a', 'k_') into token 'ak_' with frequency 30\n",
      "Merged pair ('j', 'u') into token 'ju' with frequency 30\n",
      "Merged pair ('shu', 'r') into token 'shur' with frequency 30\n",
      "Merged pair ('s', 'a_') into token 'sa_' with frequency 30\n",
      "Merged pair ('kh', 'e') into token 'khe' with frequency 30\n",
      "Merged pair ('e', 's_') into token 'es_' with frequency 30\n",
      "Merged pair ('me', 'ri_') into token 'meri_' with frequency 29\n",
      "Merged pair ('wa', 'han_') into token 'wahan_' with frequency 29\n",
      "Merged pair ('ba', 'd_') into token 'bad_' with frequency 29\n",
      "Merged pair ('ca', 'f') into token 'caf' with frequency 29\n",
      "Merged pair ('g', 'y') into token 'gy' with frequency 29\n",
      "Merged pair ('bj', 'y_') into token 'bjy_' with frequency 28\n",
      "Merged pair ('ma', 'z') into token 'maz' with frequency 28\n",
      "Merged pair ('dek', 'ha_') into token 'dekha_' with frequency 28\n",
      "Merged pair ('tho', 'ra_') into token 'thora_' with frequency 28\n",
      "Merged pair ('ha', 'm_') into token 'ham_' with frequency 28\n",
      "Merged pair ('a', 'da_') into token 'ada_' with frequency 28\n",
      "Merged pair ('u', 'th') into token 'uth' with frequency 27\n",
      "Merged pair ('ni', 'kal_') into token 'nikal_' with frequency 27\n",
      "Merged pair ('fre', 'sh_') into token 'fresh_' with frequency 27\n",
      "Merged pair ('n', 'ch_') into token 'nch_' with frequency 27\n",
      "Merged pair ('re', 'e') into token 'ree' with frequency 27\n",
      "Merged pair ('j', 'a_') into token 'ja_' with frequency 27\n",
      "Merged pair ('shur', 'u_') into token 'shuru_' with frequency 27\n",
      "Merged pair ('caf', 'e_') into token 'cafe_' with frequency 27\n",
      "Merged pair ('cha', 'i_') into token 'chai_' with frequency 27\n",
      "Merged pair ('ma', 'ine_') into token 'maine_' with frequency 27\n",
      "Merged pair ('n', 'ee') into token 'nee' with frequency 27\n",
      "Merged pair ('g', 'i_') into token 'gi_' with frequency 27\n",
      "Merged pair ('to', 'u_') into token 'tou_' with frequency 26\n",
      "Merged pair ('me', 'h') into token 'meh' with frequency 26\n",
      "Merged pair ('me', 'ne_') into token 'mene_' with frequency 26\n",
      "Merged pair ('be', 'th_') into token 'beth_' with frequency 26\n",
      "Merged pair ('muj', 'he_') into token 'mujhe_' with frequency 26\n",
      "Merged pair ('d', 'iya_') into token 'diya_' with frequency 26\n",
      "Merged pair ('hu', 'i_') into token 'hui_' with frequency 26\n",
      "Merged pair ('w', 'o_') into token 'wo_' with frequency 26\n",
      "Merged pair ('a', 'g') into token 'ag' with frequency 26\n",
      "Merged pair ('ay', 'i_') into token 'ayi_' with frequency 26\n",
      "Merged pair ('ba', 'n') into token 'ban' with frequency 26\n",
      "Merged pair ('w', 'a_') into token 'wa_' with frequency 26\n",
      "Merged pair ('m', 'aa') into token 'maa' with frequency 26\n",
      "Merged pair ('ho', 'ste') into token 'hoste' with frequency 26\n",
      "Merged pair ('hoste', 'l_') into token 'hostel_' with frequency 26\n",
      "Merged pair ('3', '_') into token '3_' with frequency 25\n",
      "Merged pair ('s', 's_') into token 'ss_' with frequency 25\n",
      "Merged pair ('s', 'i_') into token 'si_' with frequency 25\n",
      "Merged pair ('ha', 'm') into token 'ham' with frequency 25\n",
      "Merged pair ('7', '_') into token '7_' with frequency 25\n",
      "Merged pair ('tay', 'ar_') into token 'tayar_' with frequency 25\n",
      "Merged pair ('6', '_') into token '6_' with frequency 25\n",
      "Merged pair ('p', 'u') into token 'pu' with frequency 25\n",
      "Merged pair ('wa', 'q') into token 'waq' with frequency 25\n",
      "Merged pair ('y', 'e_') into token 'ye_' with frequency 25\n",
      "Merged pair ('pa', 's_') into token 'pas_' with frequency 25\n",
      "Merged pair ('8', '_') into token '8_' with frequency 24\n",
      "Merged pair ('l', 'p_') into token 'lp_' with frequency 24\n",
      "Merged pair ('po', 'han') into token 'pohan' with frequency 24\n",
      "Merged pair ('b', 'u') into token 'bu' with frequency 24\n",
      "Merged pair ('1', '1') into token '11' with frequency 24\n",
      "Merged pair ('u', 'n_') into token 'un_' with frequency 24\n",
      "Merged pair ('a', 'm') into token 'am' with frequency 24\n",
      "Merged pair ('a', 't') into token 'at' with frequency 24\n",
      "Merged pair ('at', 'te') into token 'atte' with frequency 24\n",
      "Merged pair ('c', 'e_') into token 'ce_' with frequency 24\n",
      "Merged pair ('nee', 'nd_') into token 'neend_' with frequency 24\n",
      "Merged pair ('1', '1_') into token '11_' with frequency 24\n",
      "Merged pair ('h', 'e') into token 'he' with frequency 23\n",
      "Merged pair ('lectu', 're_') into token 'lecture_' with frequency 23\n",
      "Merged pair ('ha', 't_') into token 'hat_' with frequency 23\n",
      "Merged pair ('ho', 'o') into token 'hoo' with frequency 23\n",
      "Merged pair ('la', 'te_') into token 'late_' with frequency 23\n",
      "Merged pair ('fre', 'e_') into token 'free_' with frequency 23\n",
      "Merged pair ('atte', 'nd_') into token 'attend_' with frequency 23\n",
      "Merged pair ('de', 'kh') into token 'dekh' with frequency 23\n",
      "Merged pair ('baa', 't_') into token 'baat_' with frequency 23\n",
      "Merged pair ('pho', 'ne_') into token 'phone_' with frequency 23\n",
      "Merged pair ('u', 'se_') into token 'use_' with frequency 23\n",
      "Merged pair ('aa', 'm_') into token 'aam_' with frequency 23\n",
      "Merged pair ('wa', 'pas_') into token 'wapas_' with frequency 23\n",
      "Merged pair ('la', 'g_') into token 'lag_' with frequency 23\n",
      "Merged pair ('ma', 'in') into token 'main' with frequency 23\n",
      "Merged pair ('a', 'l') into token 'al' with frequency 22\n",
      "Merged pair ('ju', 'm') into token 'jum' with frequency 22\n",
      "Merged pair ('ka', 'p') into token 'kap' with frequency 22\n",
      "Merged pair ('e', 'n') into token 'en' with frequency 22\n",
      "Merged pair ('waq', 't_') into token 'waqt_' with frequency 22\n",
      "Merged pair ('u', 'thi_') into token 'uthi_' with frequency 22\n",
      "Merged pair ('k', 'ya_') into token 'kya_' with frequency 22\n",
      "Merged pair ('b', 're') into token 'bre' with frequency 22\n",
      "Merged pair ('o', 'o') into token 'oo' with frequency 22\n",
      "Merged pair ('j', 'ec') into token 'jec' with frequency 22\n",
      "Merged pair ('l', 'un') into token 'lun' with frequency 22\n",
      "Merged pair ('9', '_') into token '9_' with frequency 21\n",
      "Merged pair ('ha', 'in_') into token 'hain_' with frequency 21\n",
      "Merged pair ('n', 'lp_') into token 'nlp_' with frequency 21\n",
      "Merged pair ('co', 'm') into token 'com' with frequency 21\n",
      "Merged pair ('g', 'han') into token 'ghan' with frequency 21\n",
      "Merged pair ('te', 'in_') into token 'tein_' with frequency 21\n",
      "Merged pair ('assignme', 'nt_') into token 'assignment_' with frequency 21\n",
      "Merged pair ('a', 'cha_') into token 'acha_' with frequency 21\n",
      "Merged pair ('pro', 'jec') into token 'projec' with frequency 21\n",
      "Merged pair ('k', 'i') into token 'ki' with frequency 21\n",
      "Merged pair ('a', 'l_') into token 'al_' with frequency 21\n",
      "Merged pair ('o', 'r') into token 'or' with frequency 20\n",
      "Merged pair ('mi', 'l_') into token 'mil_' with frequency 20\n",
      "Merged pair ('sc', 'ro') into token 'scro' with frequency 20\n",
      "Merged pair ('ba', 'n_') into token 'ban_' with frequency 20\n",
      "Merged pair ('o', 'u') into token 'ou' with frequency 20\n",
      "Merged pair ('roo', 'm_') into token 'room_' with frequency 20\n",
      "Merged pair ('ar', 'y_') into token 'ary_' with frequency 20\n",
      "Merged pair ('d', 'e_') into token 'de_' with frequency 20\n",
      "Merged pair ('is', 'liye_') into token 'isliye_' with frequency 20\n",
      "Merged pair ('lun', 'ch_') into token 'lunch_' with frequency 20\n",
      "Merged pair ('main', 'ay_') into token 'mainay_' with frequency 20\n",
      "Merged pair ('p', 'er') into token 'per' with frequency 19\n",
      "Merged pair ('g', 'e_') into token 'ge_' with frequency 19\n",
      "Merged pair ('la', 'ga_') into token 'laga_' with frequency 19\n",
      "Merged pair ('aa', 'r_') into token 'aar_' with frequency 19\n",
      "Merged pair ('bo', 'hat_') into token 'bohat_' with frequency 19\n",
      "Merged pair ('k', 'y') into token 'ky' with frequency 19\n",
      "Merged pair ('ri', 'b_') into token 'rib_' with frequency 19\n",
      "Merged pair ('gu', 'z') into token 'guz' with frequency 19\n",
      "Merged pair ('ap', 'na_') into token 'apna_' with frequency 19\n",
      "Merged pair ('mi', 'l') into token 'mil' with frequency 19\n",
      "Merged pair ('un', 'i_') into token 'uni_' with frequency 19\n",
      "Merged pair ('th', 'e_') into token 'the_' with frequency 19\n",
      "Merged pair ('ko', 'i_') into token 'koi_' with frequency 19\n",
      "Merged pair ('x', '_') into token 'x_' with frequency 19\n",
      "Merged pair ('s', 'ho') into token 'sho' with frequency 18\n",
      "Merged pair ('p', 'i') into token 'pi' with frequency 18\n",
      "Merged pair ('t', 'k_') into token 'tk_' with frequency 18\n",
      "Merged pair ('bre', 'ak_') into token 'break_' with frequency 18\n",
      "Merged pair ('k', 'ha_') into token 'kha_' with frequency 18\n",
      "Merged pair ('4', '_') into token '4_' with frequency 18\n",
      "Merged pair ('kha', 'nay_') into token 'khanay_' with frequency 18\n",
      "Merged pair ('s', 'ay_') into token 'say_' with frequency 18\n",
      "Merged pair ('h', 'ay_') into token 'hay_' with frequency 17\n",
      "Merged pair ('so', 'o') into token 'soo' with frequency 17\n",
      "Merged pair ('ee', 'n_') into token 'een_' with frequency 17\n",
      "Merged pair ('d', 'in') into token 'din' with frequency 17\n",
      "Merged pair ('st', 'ar') into token 'star' with frequency 17\n",
      "Merged pair ('11', '30_') into token '1130_' with frequency 17\n",
      "Merged pair ('ma', 'gh') into token 'magh' with frequency 17\n",
      "Merged pair ('c', 'hi_') into token 'chi_' with frequency 17\n",
      "Merged pair ('c', 'hu') into token 'chu' with frequency 17\n",
      "Merged pair ('a', 'bhi_') into token 'abhi_' with frequency 17\n",
      "Merged pair ('wal', 'on_') into token 'walon_' with frequency 17\n",
      "Merged pair ('kap', 'ray_') into token 'kapray_' with frequency 17\n",
      "Merged pair ('ka', 'm_') into token 'kam_' with frequency 17\n",
      "Merged pair ('mo', 'bi') into token 'mobi' with frequency 17\n",
      "Merged pair ('mobi', 'le_') into token 'mobile_' with frequency 17\n",
      "Merged pair ('ar', 'aam_') into token 'araam_' with frequency 17\n",
      "Merged pair ('khe', 'l') into token 'khel' with frequency 17\n",
      "Merged pair ('aa', 'ke_') into token 'aake_' with frequency 17\n",
      "Merged pair ('us', 'kay_') into token 'uskay_' with frequency 17\n",
      "Merged pair ('ba', 'ra_') into token 'bara_' with frequency 16\n",
      "Merged pair ('ho', 't_') into token 'hot_' with frequency 16\n",
      "Merged pair ('ni', 'k') into token 'nik' with frequency 16\n",
      "Merged pair ('star', 't_') into token 'start_' with frequency 16\n",
      "Merged pair ('a', 'nd_') into token 'and_' with frequency 16\n",
      "Merged pair ('scro', 'll_') into token 'scroll_' with frequency 16\n",
      "Merged pair ('sa', 'ma') into token 'sama' with frequency 16\n",
      "Merged pair ('i', 't') into token 'it' with frequency 16\n",
      "Merged pair ('magh', 'rib_') into token 'maghrib_' with frequency 16\n",
      "Merged pair ('wal', 'k_') into token 'walk_' with frequency 16\n",
      "Merged pair ('ga', 'e_') into token 'gae_' with frequency 16\n",
      "Merged pair ('po', 'o') into token 'poo' with frequency 16\n",
      "Merged pair ('k', 'h_') into token 'kh_' with frequency 16\n",
      "Merged pair ('b', 'a_') into token 'ba_' with frequency 16\n",
      "Merged pair ('baa', 'tein_') into token 'baatein_' with frequency 16\n",
      "Merged pair ('sha', 'am_') into token 'shaam_' with frequency 16\n",
      "Merged pair ('ar', 'am_') into token 'aram_' with frequency 16\n",
      "Merged pair ('gy', 'm_') into token 'gym_' with frequency 16\n",
      "Merged pair ('k', 'hu') into token 'khu' with frequency 16\n",
      "Merged pair ('projec', 't_') into token 'project_' with frequency 16\n",
      "Merged pair ('so', 'cha_') into token 'socha_' with frequency 16\n",
      "Merged pair ('ho', 'ne_') into token 'hone_' with frequency 16\n",
      "Merged pair ('y', 'a') into token 'ya' with frequency 16\n",
      "Merged pair ('m', 'ay_') into token 'may_' with frequency 16\n",
      "Merged pair ('e', 'n_') into token 'en_' with frequency 15\n",
      "Merged pair ('din', 'n') into token 'dinn' with frequency 15\n",
      "Merged pair ('dinn', 'er_') into token 'dinner_' with frequency 15\n",
      "Merged pair ('c', 'e') into token 'ce' with frequency 15\n",
      "Merged pair ('dost', 'o_') into token 'dosto_' with frequency 15\n",
      "Merged pair ('a', 'aya_') into token 'aaya_' with frequency 15\n",
      "Merged pair ('p', 'd') into token 'pd' with frequency 15\n",
      "Merged pair ('pd', 'c_') into token 'pdc_' with frequency 15\n",
      "Merged pair ('me', 'e') into token 'mee' with frequency 15\n",
      "Merged pair ('b', 'r') into token 'br' with frequency 15\n",
      "Merged pair ('ham', 'ne_') into token 'hamne_' with frequency 15\n",
      "Merged pair ('ba', 'i') into token 'bai' with frequency 15\n",
      "Merged pair ('n', 'ts_') into token 'nts_' with frequency 15\n",
      "Merged pair ('am', 'i_') into token 'ami_' with frequency 15\n",
      "Merged pair ('re', 'la') into token 'rela' with frequency 15\n",
      "Merged pair ('mo', 'vi') into token 'movi' with frequency 15\n",
      "Merged pair ('movi', 'e_') into token 'movie_' with frequency 15\n",
      "Merged pair ('ha', 'l') into token 'hal' with frequency 15\n",
      "Merged pair ('d', 'ia_') into token 'dia_' with frequency 15\n",
      "Merged pair ('p', 'la') into token 'pla' with frequency 15\n",
      "Merged pair ('kar', 'na_') into token 'karna_' with frequency 15\n",
      "Merged pair ('ja', 'b_') into token 'jab_' with frequency 15\n",
      "Merged pair ('ne', 'i_') into token 'nei_' with frequency 15\n",
      "Merged pair ('ke', 'i_') into token 'kei_' with frequency 15\n",
      "Merged pair ('la', 'r') into token 'lar' with frequency 14\n",
      "Merged pair ('bo', 'hot_') into token 'bohot_' with frequency 14\n",
      "Merged pair ('d', 'ay_') into token 'day_' with frequency 14\n",
      "Merged pair ('ma', 'h_') into token 'mah_' with frequency 14\n",
      "Merged pair ('mi', 'la_') into token 'mila_' with frequency 14\n",
      "Merged pair ('pohan', 'ch_') into token 'pohanch_' with frequency 14\n",
      "Merged pair ('t', 'ing_') into token 'ting_' with frequency 14\n",
      "Merged pair ('ph', 'r_') into token 'phr_' with frequency 14\n",
      "Merged pair ('is', 'ha_') into token 'isha_' with frequency 14\n",
      "Merged pair ('b', 'd_') into token 'bd_' with frequency 14\n",
      "Merged pair ('cha', 'li_') into token 'chali_' with frequency 14\n",
      "Merged pair ('r', 'hi_') into token 'rhi_' with frequency 14\n",
      "Merged pair ('b', 'e_') into token 'be_' with frequency 14\n",
      "Merged pair ('ma', 'ma_') into token 'mama_' with frequency 14\n",
      "Merged pair ('f', 'e') into token 'fe' with frequency 14\n",
      "Merged pair ('ba', 's_') into token 'bas_' with frequency 14\n",
      "Merged pair ('t', 'iv') into token 'tiv' with frequency 14\n",
      "Merged pair ('ba', 'h') into token 'bah' with frequency 14\n",
      "Merged pair ('assignme', 'nts_') into token 'assignments_' with frequency 14\n",
      "Merged pair ('par', 'h') into token 'parh' with frequency 14\n",
      "Merged pair ('s', 'y_') into token 'sy_' with frequency 14\n",
      "Merged pair ('maa', 'n_') into token 'maan_' with frequency 14\n",
      "Merged pair ('ro', 'u') into token 'rou' with frequency 13\n",
      "Merged pair ('la', 'h_') into token 'lah_' with frequency 13\n",
      "Merged pair ('jum', 'mah_') into token 'jummah_' with frequency 13\n",
      "Merged pair ('t', 'u_') into token 'tu_' with frequency 13\n",
      "Merged pair ('re', 'st_') into token 'rest_' with frequency 13\n",
      "Merged pair ('ti', 'on_') into token 'tion_' with frequency 13\n",
      "Merged pair ('sa', 'i_') into token 'sai_' with frequency 13\n",
      "Merged pair ('so', 'nay_') into token 'sonay_' with frequency 13\n",
      "Merged pair ('shu', 'p_') into token 'shup_' with frequency 13\n",
      "Merged pair ('a', 'j') into token 'aj' with frequency 13\n",
      "Merged pair ('na', 'h') into token 'nah' with frequency 13\n",
      "Merged pair ('b', 'ee') into token 'bee' with frequency 13\n",
      "Merged pair ('1', '2_') into token '12_' with frequency 13\n",
      "Merged pair ('ja', 'na_') into token 'jana_' with frequency 13\n",
      "Merged pair ('z', 'a') into token 'za' with frequency 13\n",
      "Merged pair ('a', 'b') into token 'ab' with frequency 13\n",
      "Merged pair ('ar', 'a_') into token 'ara_' with frequency 13\n",
      "Merged pair ('2', '30_') into token '230_' with frequency 13\n",
      "Merged pair ('n', 'hi_') into token 'nhi_' with frequency 13\n",
      "Merged pair ('ka', 'm') into token 'kam' with frequency 13\n",
      "Merged pair ('8', '30_') into token '830_' with frequency 13\n",
      "Merged pair ('li', 'br') into token 'libr' with frequency 13\n",
      "Merged pair ('libr', 'ary_') into token 'library_' with frequency 13\n",
      "Merged pair ('ch', 'ee') into token 'chee' with frequency 13\n",
      "Merged pair ('bah', 'ir_') into token 'bahir_' with frequency 13\n",
      "Merged pair ('ba', 'ba_') into token 'baba_' with frequency 13\n",
      "Merged pair ('ka', 'fi_') into token 'kafi_' with frequency 13\n",
      "Merged pair ('la', 'b_') into token 'lab_' with frequency 13\n",
      "Merged pair ('ci', 'al_') into token 'cial_' with frequency 13\n",
      "Merged pair ('wa', 'ja') into token 'waja' with frequency 13\n",
      "Merged pair ('waja', 'h_') into token 'wajah_' with frequency 13\n",
      "Merged pair ('h', 'y_') into token 'hy_' with frequency 13\n",
      "Merged pair ('la', 'p') into token 'lap' with frequency 13\n",
      "Merged pair ('lap', 'to') into token 'lapto' with frequency 13\n",
      "Merged pair ('lapto', 'p_') into token 'laptop_' with frequency 13\n",
      "Merged pair ('peh', 'lay_') into token 'pehlay_' with frequency 13\n",
      "Merged pair ('r', 'y_') into token 'ry_' with frequency 13\n",
      "Merged pair ('ca', 'll_') into token 'call_' with frequency 13\n",
      "Merged pair ('kar', 'nay_') into token 'karnay_' with frequency 13\n",
      "Merged pair ('1', '5_') into token '15_' with frequency 12\n",
      "Merged pair ('u', 'd') into token 'ud' with frequency 12\n",
      "Merged pair ('r', 'f_') into token 'rf_' with frequency 12\n",
      "Merged pair ('j', 'is_') into token 'jis_' with frequency 12\n",
      "Merged pair ('ap', 'nay_') into token 'apnay_' with frequency 12\n",
      "Merged pair ('n', 'o_') into token 'no_' with frequency 12\n",
      "Merged pair ('c', 'k_') into token 'ck_' with frequency 12\n",
      "Merged pair ('f', 'ar') into token 'far' with frequency 12\n",
      "Merged pair ('p', 'i_') into token 'pi_' with frequency 12\n",
      "Merged pair ('in', 'st') into token 'inst' with frequency 12\n",
      "Merged pair ('par', 'ha_') into token 'parha_' with frequency 12\n",
      "Merged pair ('gh', 'r_') into token 'ghr_' with frequency 12\n",
      "Merged pair ('mi', 'ly_') into token 'mily_' with frequency 12\n",
      "Merged pair ('ty', 'ar_') into token 'tyar_' with frequency 12\n",
      "Merged pair ('di', 'p_') into token 'dip_' with frequency 12\n",
      "Merged pair ('7', '30_') into token '730_' with frequency 12\n",
      "Merged pair ('y', 'ou') into token 'you' with frequency 12\n",
      "Merged pair ('you', 'tu') into token 'youtu' with frequency 12\n",
      "Merged pair ('youtu', 'be_') into token 'youtube_' with frequency 12\n",
      "Merged pair ('ba', 'na') into token 'bana' with frequency 12\n",
      "Merged pair ('j', 'is') into token 'jis' with frequency 12\n",
      "Merged pair ('in', 'te') into token 'inte' with frequency 12\n",
      "Merged pair ('a', 'b_') into token 'ab_' with frequency 12\n",
      "Merged pair ('c', 'ho') into token 'cho' with frequency 12\n",
      "Merged pair ('ke', 'h_') into token 'keh_' with frequency 12\n",
      "Merged pair ('k', 'er_') into token 'ker_' with frequency 12\n",
      "Merged pair ('o', 'f') into token 'of' with frequency 12\n",
      "Merged pair ('re', 's_') into token 'res_' with frequency 12\n",
      "Merged pair ('hu', 'wa_') into token 'huwa_' with frequency 12\n",
      "Merged pair ('t', 'ar') into token 'tar' with frequency 12\n",
      "Merged pair ('na', 'l_') into token 'nal_' with frequency 12\n",
      "Merged pair ('ba', 'har_') into token 'bahar_' with frequency 12\n",
      "Merged pair ('pla', 'n_') into token 'plan_' with frequency 12\n",
      "Merged pair ('ch', 'ec') into token 'chec' with frequency 12\n",
      "Merged pair ('g', 'ay_') into token 'gay_' with frequency 12\n",
      "Merged pair ('i', 't_') into token 'it_' with frequency 12\n",
      "Merged pair ('ap', 'ny_') into token 'apny_' with frequency 12\n",
      "Merged pair ('ky', 'un') into token 'kyun' with frequency 12\n",
      "Merged pair ('ka', 'ha_') into token 'kaha_' with frequency 12\n",
      "Merged pair ('t', 'or_') into token 'tor_' with frequency 11\n",
      "Merged pair ('pa', 'ss_') into token 'pass_' with frequency 11\n",
      "Merged pair ('si', 'rf_') into token 'sirf_' with frequency 11\n",
      "Merged pair ('maz', 'a_') into token 'maza_' with frequency 11\n",
      "Merged pair ('s', 'ir_') into token 'sir_' with frequency 11\n",
      "Merged pair ('hu', 'w') into token 'huw' with frequency 11\n",
      "Merged pair ('g', 'h_') into token 'gh_' with frequency 11\n",
      "Merged pair ('z', 'ar_') into token 'zar_' with frequency 11\n",
      "Merged pair ('st', 'o') into token 'sto' with frequency 11\n",
      "Merged pair ('ree', 'ban_') into token 'reeban_' with frequency 11\n",
      "Merged pair ('me', 'ra_') into token 'mera_' with frequency 11\n",
      "Merged pair ('fa', 'mily_') into token 'family_' with frequency 11\n",
      "Merged pair ('po', 'hu') into token 'pohu' with frequency 11\n",
      "Merged pair ('ha', 'ma') into token 'hama' with frequency 11\n",
      "Merged pair ('com', 'p') into token 'comp' with frequency 11\n",
      "Merged pair ('le', 'te_') into token 'lete_' with frequency 11\n",
      "Merged pair ('wa', 'i_') into token 'wai_' with frequency 11\n",
      "Merged pair ('gy', 'i_') into token 'gyi_' with frequency 11\n",
      "Merged pair ('us', 's_') into token 'uss_' with frequency 11\n",
      "Merged pair ('an', 'n_') into token 'ann_' with frequency 11\n",
      "Merged pair ('par', 'h_') into token 'parh_' with frequency 11\n",
      "Merged pair ('ho', 'ti_') into token 'hoti_' with frequency 11\n",
      "Merged pair ('kha', 'a') into token 'khaa' with frequency 11\n",
      "Merged pair ('l', 'ly_') into token 'lly_' with frequency 11\n",
      "Merged pair ('ban', 'aya_') into token 'banaya_' with frequency 11\n",
      "Merged pair ('fa', 'j') into token 'faj' with frequency 11\n",
      "Merged pair ('faj', 'r_') into token 'fajr_' with frequency 11\n",
      "Merged pair ('re', 'vi') into token 'revi' with frequency 11\n",
      "Merged pair ('a', 'lar') into token 'alar' with frequency 11\n",
      "Merged pair ('si', 'on_') into token 'sion_' with frequency 11\n",
      "Merged pair ('sub', 'a_') into token 'suba_' with frequency 11\n",
      "Merged pair ('kar', 'te_') into token 'karte_' with frequency 11\n",
      "Merged pair ('rela', 'x_') into token 'relax_' with frequency 11\n",
      "Merged pair ('tiv', 'e_') into token 'tive_' with frequency 11\n",
      "Merged pair ('dek', 'hi_') into token 'dekhi_' with frequency 11\n",
      "Merged pair ('chec', 'k_') into token 'check_' with frequency 11\n",
      "Merged pair ('ne', 't') into token 'net' with frequency 11\n",
      "Merged pair ('w', 'or') into token 'wor' with frequency 11\n",
      "Merged pair ('iy', 'a') into token 'iya' with frequency 11\n",
      "Merged pair ('la', 'gi_') into token 'lagi_' with frequency 11\n",
      "Merged pair ('bee', 'ch_') into token 'beech_' with frequency 11\n",
      "Merged pair ('kha', 'ta') into token 'khata' with frequency 11\n",
      "Merged pair ('khata', 'm_') into token 'khatam_' with frequency 11\n",
      "Merged pair ('ta', 'b') into token 'tab' with frequency 11\n",
      "Merged pair ('ga', 'ay_') into token 'gaay_' with frequency 10\n",
      "Merged pair ('hu', 'm') into token 'hum' with frequency 10\n",
      "Merged pair ('cha', 'n') into token 'chan' with frequency 10\n",
      "Merged pair ('k', 's_') into token 'ks_' with frequency 10\n",
      "Merged pair ('f', 'u') into token 'fu' with frequency 10\n",
      "Merged pair ('w', '_') into token 'w_' with frequency 10\n",
      "Merged pair ('po', 'nch_') into token 'ponch_' with frequency 10\n",
      "Merged pair ('1', '2') into token '12' with frequency 10\n",
      "Merged pair ('b', 'hai_') into token 'bhai_' with frequency 10\n",
      "Merged pair ('co', 'u') into token 'cou' with frequency 10\n",
      "Merged pair ('wa', 't_') into token 'wat_' with frequency 10\n",
      "Merged pair ('so', 'gaya_') into token 'sogaya_' with frequency 10\n",
      "Merged pair ('aj', 'j_') into token 'ajj_' with frequency 10\n",
      "Merged pair ('i', 'st') into token 'ist' with frequency 10\n",
      "Merged pair ('far', 'i') into token 'fari' with frequency 10\n",
      "Merged pair ('g', 'e') into token 'ge' with frequency 10\n",
      "Merged pair ('1', '0') into token '10' with frequency 10\n",
      "Merged pair ('ho', 'gaya_') into token 'hogaya_' with frequency 10\n",
      "Merged pair ('ba', 'll_') into token 'ball_' with frequency 10\n",
      "Merged pair ('na', 'sc') into token 'nasc' with frequency 10\n",
      "Merged pair ('nasc', 'on_') into token 'nascon_' with frequency 10\n",
      "Merged pair ('comp', 'lete_') into token 'complete_' with frequency 10\n",
      "Merged pair ('ba', 'na_') into token 'bana_' with frequency 10\n",
      "Merged pair ('ne', 't_') into token 'net_' with frequency 10\n",
      "Merged pair ('o', 's') into token 'os' with frequency 10\n",
      "Merged pair ('bai', 'th_') into token 'baith_' with frequency 10\n",
      "Merged pair ('ty', 'ari_') into token 'tyari_' with frequency 10\n",
      "Merged pair ('of', 'fi') into token 'offi' with frequency 10\n",
      "Merged pair ('offi', 'ce_') into token 'office_' with frequency 10\n",
      "Merged pair ('p', 'm_') into token 'pm_' with frequency 10\n",
      "Merged pair ('alar', 'm_') into token 'alarm_' with frequency 10\n",
      "Merged pair ('ghan', 'tay_') into token 'ghantay_' with frequency 10\n",
      "Merged pair ('be', 'd_') into token 'bed_' with frequency 10\n",
      "Merged pair ('f', 'ee') into token 'fee' with frequency 10\n",
      "Merged pair ('lectu', 'res_') into token 'lectures_' with frequency 10\n",
      "Merged pair ('ra', 'm_') into token 'ram_' with frequency 10\n",
      "Merged pair ('sa', 't_') into token 'sat_' with frequency 10\n",
      "Merged pair ('se', 't_') into token 'set_' with frequency 10\n",
      "Merged pair ('aa', 'd_') into token 'aad_' with frequency 10\n",
      "Merged pair ('me', 's_') into token 'mes_' with frequency 10\n",
      "Merged pair ('cha', 'lay_') into token 'chalay_' with frequency 10\n",
      "Merged pair ('wa', 'na_') into token 'wana_' with frequency 10\n",
      "Merged pair ('kyun', 'ki_') into token 'kyunki_' with frequency 10\n",
      "Merged pair ('is', 'i_') into token 'isi_' with frequency 10\n",
      "Merged pair ('soo', 's_') into token 'soos_' with frequency 10\n",
      "Merged pair ('ka', 'e_') into token 'kae_' with frequency 10\n",
      "Merged pair ('a', 'or_') into token 'aor_' with frequency 10\n",
      "Merged pair ('a', 'd') into token 'ad' with frequency 9\n",
      "Merged pair ('ta', 'k') into token 'tak' with frequency 9\n",
      "Merged pair ('peh', 'le_') into token 'pehle_' with frequency 9\n",
      "Merged pair ('wa', 'ja_') into token 'waja_' with frequency 9\n",
      "Merged pair ('sha', 'm_') into token 'sham_' with frequency 9\n",
      "Merged pair ('gu', 'p_') into token 'gup_' with frequency 9\n",
      "Merged pair ('ee', 'b_') into token 'eeb_' with frequency 9\n",
      "Merged pair ('fari', 'gh_') into token 'farigh_' with frequency 9\n",
      "Merged pair ('2', '0_') into token '20_' with frequency 9\n",
      "Merged pair ('po', 'n') into token 'pon' with frequency 9\n",
      "Merged pair ('w', 'n_') into token 'wn_' with frequency 9\n",
      "Merged pair ('bo', 'o') into token 'boo' with frequency 9\n",
      "Merged pair ('boo', 'k_') into token 'book_' with frequency 9\n",
      "Merged pair ('mee', 'ting_') into token 'meeting_' with frequency 9\n",
      "Merged pair ('c', 'net_') into token 'cnet_' with frequency 9\n",
      "Merged pair ('n', 'd') into token 'nd' with frequency 9\n",
      "Merged pair ('k', 'er') into token 'ker' with frequency 9\n",
      "Merged pair ('j', 'aa') into token 'jaa' with frequency 9\n",
      "Merged pair ('th', 'ay_') into token 'thay_' with frequency 9\n",
      "Merged pair ('ha', 'th_') into token 'hath_' with frequency 9\n",
      "Merged pair ('as', 'r_') into token 'asr_' with frequency 9\n",
      "Merged pair ('so', 'o_') into token 'soo_' with frequency 9\n",
      "Merged pair ('so', 'ya_') into token 'soya_' with frequency 9\n",
      "Merged pair ('muj', 'hay_') into token 'mujhay_' with frequency 9\n",
      "Merged pair ('is', 'c') into token 'isc' with frequency 9\n",
      "Merged pair ('i', 'ra') into token 'ira' with frequency 9\n",
      "Merged pair ('hal', 'ka_') into token 'halka_' with frequency 9\n",
      "Merged pair ('se', 'ar') into token 'sear' with frequency 9\n",
      "Merged pair ('sear', 'ch_') into token 'search_' with frequency 9\n",
      "Merged pair ('e', 'x') into token 'ex' with frequency 9\n",
      "Merged pair ('fee', 'l_') into token 'feel_' with frequency 9\n",
      "Merged pair ('be', 'h') into token 'beh' with frequency 9\n",
      "Merged pair ('peh', 'li_') into token 'pehli_' with frequency 9\n",
      "Merged pair ('sama', 'j') into token 'samaj' with frequency 9\n",
      "Merged pair ('f', 'oo') into token 'foo' with frequency 9\n",
      "Merged pair ('ga', 'me_') into token 'game_' with frequency 9\n",
      "Merged pair ('ga', 'r_') into token 'gar_' with frequency 9\n",
      "Merged pair ('kr', 'ny_') into token 'krny_' with frequency 9\n",
      "Merged pair ('khel', 'ne_') into token 'khelne_' with frequency 9\n",
      "Merged pair ('bo', 'h') into token 'boh' with frequency 9\n",
      "Merged pair ('boh', 't_') into token 'boht_' with frequency 9\n",
      "Merged pair ('w', 'aa') into token 'waa' with frequency 9\n",
      "Merged pair ('ga', 'mes_') into token 'games_' with frequency 9\n",
      "Merged pair ('t', 'aake_') into token 'taake_' with frequency 9\n",
      "Merged pair ('ba', 'd') into token 'bad' with frequency 9\n",
      "Merged pair ('ma', 's') into token 'mas' with frequency 9\n",
      "Merged pair ('z', 'u') into token 'zu' with frequency 9\n",
      "Merged pair ('meh', 'soos_') into token 'mehsoos_' with frequency 9\n",
      "Merged pair ('do', 'bara_') into token 'dobara_' with frequency 9\n",
      "Merged pair ('us', 'h_') into token 'ush_' with frequency 9\n",
      "Merged pair ('na', 'lly_') into token 'nally_' with frequency 9\n",
      "Merged pair ('ho', 'ta_') into token 'hota_' with frequency 9\n",
      "Merged pair ('th', 'y_') into token 'thy_' with frequency 8\n",
      "Merged pair ('nash', 'tay_') into token 'nashtay_' with frequency 8\n",
      "Merged pair ('f', 'ri') into token 'fri' with frequency 8\n",
      "Merged pair ('me', 're_') into token 'mere_' with frequency 8\n",
      "Merged pair ('a', 'ch') into token 'ach' with frequency 8\n",
      "Merged pair ('o', 'on_') into token 'oon_' with frequency 8\n",
      "Merged pair ('n', 's_') into token 'ns_' with frequency 8\n",
      "Merged pair ('meh', 'ma') into token 'mehma' with frequency 8\n",
      "Merged pair ('par', 'a') into token 'para' with frequency 8\n",
      "Merged pair ('is', 'la') into token 'isla' with frequency 8\n",
      "Merged pair ('isla', 'ma') into token 'islama' with frequency 8\n",
      "Merged pair ('islama', 'bad_') into token 'islamabad_' with frequency 8\n",
      "Merged pair ('nah', 'aya_') into token 'nahaya_' with frequency 8\n",
      "Merged pair ('d', 'ro') into token 'dro' with frequency 8\n",
      "Merged pair ('dro', 'p_') into token 'drop_' with frequency 8\n",
      "Merged pair ('cha', 'le_') into token 'chale_' with frequency 8\n",
      "Merged pair ('re', 'st') into token 'rest' with frequency 8\n",
      "Merged pair ('kha', 'ny_') into token 'khany_' with frequency 8\n",
      "Merged pair ('w', 'o') into token 'wo' with frequency 8\n",
      "Merged pair ('a', 'sa') into token 'asa' with frequency 8\n",
      "Merged pair ('guz', 'ara_') into token 'guzara_' with frequency 8\n",
      "Merged pair ('pohu', 'n') into token 'pohun' with frequency 8\n",
      "Merged pair ('h', 'r_') into token 'hr_' with frequency 8\n",
      "Merged pair ('kr', 'ne_') into token 'krne_' with frequency 8\n",
      "Merged pair ('t', 'iy') into token 'tiy' with frequency 8\n",
      "Merged pair ('1', '00_') into token '100_' with frequency 8\n",
      "Merged pair ('r', 'ha_') into token 'rha_' with frequency 8\n",
      "Merged pair ('uth', 'ne_') into token 'uthne_' with frequency 8\n",
      "Merged pair ('f', 'fe') into token 'ffe' with frequency 8\n",
      "Merged pair ('v', 'e') into token 've' with frequency 8\n",
      "Merged pair ('f', 'y') into token 'fy' with frequency 8\n",
      "Merged pair ('fy', 'p_') into token 'fyp_' with frequency 8\n",
      "Merged pair ('ag', 'le_') into token 'agle_' with frequency 8\n",
      "Merged pair ('li', 'kh_') into token 'likh_' with frequency 8\n",
      "Merged pair ('do', 'os') into token 'doos' with frequency 8\n",
      "Merged pair ('jum', 'ma_') into token 'jumma_' with frequency 8\n",
      "Merged pair ('is', 'h_') into token 'ish_' with frequency 8\n",
      "Merged pair ('ch', 'la_') into token 'chla_' with frequency 8\n",
      "Merged pair ('dek', 'h_') into token 'dekh_' with frequency 8\n",
      "Merged pair ('a', 'c') into token 'ac' with frequency 8\n",
      "Merged pair ('tar', 'a') into token 'tara' with frequency 8\n",
      "Merged pair ('re', 'search_') into token 'research_' with frequency 8\n",
      "Merged pair ('e', 'in_') into token 'ein_' with frequency 8\n",
      "Merged pair ('d', 'ho') into token 'dho' with frequency 8\n",
      "Merged pair ('iy', 'ay_') into token 'iyay_' with frequency 8\n",
      "Merged pair ('ma', 'gar_') into token 'magar_' with frequency 8\n",
      "Merged pair ('p', 'y_') into token 'py_' with frequency 8\n",
      "Merged pair ('wa', 'li_') into token 'wali_' with frequency 8\n",
      "Merged pair ('ma', 't') into token 'mat' with frequency 8\n",
      "Merged pair ('ma', 'l_') into token 'mal_' with frequency 8\n",
      "Merged pair ('p', 'is_') into token 'pis_' with frequency 8\n",
      "Merged pair ('s', 'pe') into token 'spe' with frequency 8\n",
      "Merged pair ('ke', 'nd_') into token 'kend_' with frequency 8\n",
      "Merged pair ('l', 's_') into token 'ls_' with frequency 8\n",
      "Merged pair ('sa', 'maan_') into token 'samaan_' with frequency 8\n",
      "Merged pair ('p', 'ee') into token 'pee' with frequency 8\n",
      "Merged pair ('i', 'd_') into token 'id_' with frequency 8\n",
      "Merged pair ('ho', 'n_') into token 'hon_' with frequency 8\n",
      "Merged pair ('kar', 'tay_') into token 'kartay_' with frequency 8\n",
      "Merged pair ('ra', 'wana_') into token 'rawana_' with frequency 8\n",
      "Merged pair ('fi', 'nally_') into token 'finally_' with frequency 8\n",
      "Merged pair ('ta', 'r_') into token 'tar_' with frequency 8\n",
      "Merged pair ('a', 'd_') into token 'ad_' with frequency 8\n",
      "Merged pair ('t', 'ri') into token 'tri' with frequency 7\n",
      "Merged pair ('tri', 'p_') into token 'trip_' with frequency 7\n",
      "Merged pair ('tha', 'a_') into token 'thaa_' with frequency 7\n",
      "Merged pair ('j', 'o') into token 'jo' with frequency 7\n",
      "Merged pair ('ka', 'ay_') into token 'kaay_' with frequency 7\n",
      "Merged pair ('chan', 'ge_') into token 'change_' with frequency 7\n",
      "Merged pair ('b', 'he') into token 'bhe' with frequency 7\n",
      "Merged pair ('ty', 'aar_') into token 'tyaar_' with frequency 7\n",
      "Merged pair ('ho', 'nay_') into token 'honay_' with frequency 7\n",
      "Merged pair ('le', 'ne_') into token 'lene_' with frequency 7\n",
      "Merged pair ('aa', 'ri_') into token 'aari_' with frequency 7\n",
      "Merged pair ('tha', 'ka') into token 'thaka' with frequency 7\n",
      "Merged pair ('n', 'ce') into token 'nce' with frequency 7\n",
      "Merged pair ('sa', 'b') into token 'sab' with frequency 7\n",
      "Merged pair ('para', 'tha_') into token 'paratha_' with frequency 7\n",
      "Merged pair ('ch', 'aye_') into token 'chaye_' with frequency 7\n",
      "Merged pair ('ma', 'r') into token 'mar' with frequency 7\n",
      "Merged pair ('wa', 'ha_') into token 'waha_' with frequency 7\n",
      "Merged pair ('ta', 'l_') into token 'tal_' with frequency 7\n",
      "Merged pair ('bu', 'r') into token 'bur' with frequency 7\n",
      "Merged pair ('com', 'pu') into token 'compu' with frequency 7\n",
      "Merged pair ('ky', 'un_') into token 'kyun_' with frequency 7\n",
      "Merged pair ('asa', 'r_') into token 'asar_' with frequency 7\n",
      "Merged pair ('e', 'e_') into token 'ee_' with frequency 7\n",
      "Merged pair ('sto', 'p_') into token 'stop_' with frequency 7\n",
      "Merged pair ('ta', 'q') into token 'taq' with frequency 7\n",
      "Merged pair ('le', 'na_') into token 'lena_' with frequency 7\n",
      "Merged pair ('cou', 'r') into token 'cour' with frequency 7\n",
      "Merged pair ('kha', 'ne_') into token 'khane_' with frequency 7\n",
      "Merged pair ('u', 'tha') into token 'utha' with frequency 7\n",
      "Merged pair ('vi', 'de') into token 'vide' with frequency 7\n",
      "Merged pair ('pa', 'ta_') into token 'pata_' with frequency 7\n",
      "Merged pair ('ha', 'a') into token 'haa' with frequency 7\n",
      "Merged pair ('so', 'ne_') into token 'sone_' with frequency 7\n",
      "Merged pair ('t', 'ti_') into token 'tti_' with frequency 7\n",
      "Merged pair ('de', 'er_') into token 'deer_' with frequency 7\n",
      "Merged pair ('revi', 'se_') into token 'revise_' with frequency 7\n",
      "Merged pair ('tu', 're_') into token 'ture_' with frequency 7\n",
      "Merged pair ('p', 'a_') into token 'pa_' with frequency 7\n",
      "Merged pair ('w', 'aya_') into token 'waya_' with frequency 7\n",
      "Merged pair ('d', 'isc') into token 'disc' with frequency 7\n",
      "Merged pair ('t', 'ra') into token 'tra' with frequency 7\n",
      "Merged pair ('n', 'aye_') into token 'naye_' with frequency 7\n",
      "Merged pair ('pa', 'har_') into token 'pahar_' with frequency 7\n",
      "Merged pair ('so', 'cial_') into token 'social_' with frequency 7\n",
      "Merged pair ('me', 'dia_') into token 'media_' with frequency 7\n",
      "Merged pair ('aa', 'kar_') into token 'aakar_' with frequency 7\n",
      "Merged pair ('d', 'o_') into token 'do_' with frequency 7\n",
      "Merged pair ('c', 'u') into token 'cu' with frequency 7\n",
      "Merged pair ('foo', 't') into token 'foot' with frequency 7\n",
      "Merged pair ('foot', 'ball_') into token 'football_' with frequency 7\n",
      "Merged pair ('l', 'iyay_') into token 'liyay_' with frequency 7\n",
      "Merged pair ('k', 'ch_') into token 'kch_' with frequency 7\n",
      "Merged pair ('a', 'i_') into token 'ai_' with frequency 7\n",
      "Merged pair ('us', 'y_') into token 'usy_' with frequency 7\n",
      "Merged pair ('y', 'aad_') into token 'yaad_' with frequency 7\n",
      "Merged pair ('b', 'hoo') into token 'bhoo' with frequency 7\n",
      "Merged pair ('ra', 'n_') into token 'ran_' with frequency 7\n",
      "Merged pair ('net', 'wor') into token 'networ' with frequency 7\n",
      "Merged pair ('z', 'y') into token 'zy' with frequency 7\n",
      "Merged pair ('zy', 'ada_') into token 'zyada_' with frequency 7\n",
      "Merged pair ('k', 'isi_') into token 'kisi_' with frequency 7\n",
      "Merged pair ('mo', 'o') into token 'moo' with frequency 7\n",
      "Merged pair ('w', 'ee') into token 'wee' with frequency 7\n",
      "Merged pair ('wee', 'kend_') into token 'weekend_' with frequency 7\n",
      "Merged pair ('poo', 'ra_') into token 'poora_' with frequency 7\n",
      "Merged pair ('ka', 'sh') into token 'kash' with frequency 7\n",
      "Merged pair ('kash', 'm') into token 'kashm' with frequency 7\n",
      "Merged pair ('kashm', 'ir_') into token 'kashmir_' with frequency 7\n",
      "Merged pair ('khu', 'li_') into token 'khuli_' with frequency 7\n",
      "Merged pair ('iya', 't_') into token 'iyat_' with frequency 7\n",
      "Merged pair ('ka', 'ree') into token 'karee' with frequency 7\n",
      "Merged pair ('karee', 'b_') into token 'kareeb_' with frequency 7\n",
      "Merged pair ('saa', 'f_') into token 'saaf_' with frequency 7\n",
      "Merged pair ('ho', 'on_') into token 'hoon_' with frequency 7\n",
      "Merged pair ('na', 'i_') into token 'nai_' with frequency 7\n",
      "Merged pair ('de', 'ci') into token 'deci' with frequency 7\n",
      "Merged pair ('huw', 'i_') into token 'huwi_' with frequency 7\n",
      "Merged pair ('uth', 'na_') into token 'uthna_' with frequency 6\n",
      "Merged pair ('4', '0_') into token '40_' with frequency 6\n",
      "Merged pair ('cha', 'l_') into token 'chal_' with frequency 6\n",
      "Merged pair ('ta', 'in_') into token 'tain_' with frequency 6\n",
      "Merged pair ('ra', 'hay_') into token 'rahay_' with frequency 6\n",
      "Merged pair ('n', 'g_') into token 'ng_' with frequency 6\n",
      "Merged pair ('pi', 'c') into token 'pic' with frequency 6\n",
      "Merged pair ('g', 'rou') into token 'grou' with frequency 6\n",
      "Merged pair ('grou', 'p_') into token 'group_' with frequency 6\n",
      "Merged pair ('wap', 'si_') into token 'wapsi_' with frequency 6\n",
      "Merged pair ('ty', 'aari_') into token 'tyaari_' with frequency 6\n",
      "Merged pair ('kha', 'i') into token 'khai' with frequency 6\n",
      "Merged pair ('an', 'da_') into token 'anda_' with frequency 6\n",
      "Merged pair ('tay', 'ari_') into token 'tayari_' with frequency 6\n",
      "Merged pair ('p', 'r_') into token 'pr_' with frequency 6\n",
      "Merged pair ('q', 'ar') into token 'qar' with frequency 6\n",
      "Merged pair ('t', 'er_') into token 'ter_' with frequency 6\n",
      "Merged pair ('bur', 'g') into token 'burg' with frequency 6\n",
      "Merged pair ('ph', 'e') into token 'phe' with frequency 6\n",
      "Merged pair ('sama', 'n_') into token 'saman_' with frequency 6\n",
      "Merged pair ('taq', 'reeban_') into token 'taqreeban_' with frequency 6\n",
      "Merged pair ('l', 'ya_') into token 'lya_' with frequency 6\n",
      "Merged pair ('un', 'ke_') into token 'unke_' with frequency 6\n",
      "Merged pair ('5', '15_') into token '515_' with frequency 6\n",
      "Merged pair ('te', 's_') into token 'tes_' with frequency 6\n",
      "Merged pair ('i', 'l_') into token 'il_' with frequency 6\n",
      "Merged pair ('t', 'v') into token 'tv' with frequency 6\n",
      "Merged pair ('tv', '_') into token 'tv_' with frequency 6\n",
      "Merged pair ('6', '00_') into token '600_' with frequency 6\n",
      "Merged pair ('ta', 's') into token 'tas' with frequency 6\n",
      "Merged pair ('uth', 'aya_') into token 'uthaya_' with frequency 6\n",
      "Merged pair ('co', 'ffe') into token 'coffe' with frequency 6\n",
      "Merged pair ('coffe', 'e_') into token 'coffee_' with frequency 6\n",
      "Merged pair ('jis', 'me_') into token 'jisme_' with frequency 6\n",
      "Merged pair ('li', 'kh') into token 'likh' with frequency 6\n",
      "Merged pair ('r', 'he_') into token 'rhe_' with frequency 6\n",
      "Merged pair ('ko', 'sh') into token 'kosh' with frequency 6\n",
      "Merged pair ('kosh', 'ish_') into token 'koshish_' with frequency 6\n",
      "Merged pair ('w', 'e') into token 'we' with frequency 6\n",
      "Merged pair ('cha', 'l') into token 'chal' with frequency 6\n",
      "Merged pair ('r', 'u') into token 'ru' with frequency 6\n",
      "Merged pair ('me', 'ine_') into token 'meine_' with frequency 6\n",
      "Merged pair ('p', 'p') into token 'pp' with frequency 6\n",
      "Merged pair ('hu', 'e_') into token 'hue_' with frequency 6\n",
      "Merged pair ('pa', 'ni_') into token 'pani_' with frequency 6\n",
      "Merged pair ('na', 'ha') into token 'naha' with frequency 6\n",
      "Merged pair ('de', 'e') into token 'dee' with frequency 6\n",
      "Merged pair ('n', 'ing_') into token 'ning_' with frequency 6\n",
      "Merged pair ('baj', 'y_') into token 'bajy_' with frequency 6\n",
      "Merged pair ('do', 'no_') into token 'dono_' with frequency 6\n",
      "Merged pair ('kar', 'ke_') into token 'karke_' with frequency 6\n",
      "Merged pair ('n', 'o') into token 'no' with frequency 6\n",
      "Merged pair ('la', 'wn_') into token 'lawn_' with frequency 6\n",
      "Merged pair ('d', 'ha_') into token 'dha_' with frequency 6\n",
      "Merged pair ('ghan', 'ta_') into token 'ghanta_' with frequency 6\n",
      "Merged pair ('n', 'aa') into token 'naa' with frequency 6\n",
      "Merged pair ('g', 'ari_') into token 'gari_' with frequency 6\n",
      "Merged pair ('guz', 'ar_') into token 'guzar_' with frequency 6\n",
      "Merged pair ('l', 'ia_') into token 'lia_' with frequency 6\n",
      "Merged pair ('er', 's_') into token 'ers_' with frequency 6\n",
      "Merged pair ('inst', 'ag') into token 'instag' with frequency 6\n",
      "Merged pair ('instag', 'ram_') into token 'instagram_' with frequency 6\n",
      "Merged pair ('m', 'j') into token 'mj' with frequency 6\n",
      "Merged pair ('in', 't') into token 'int' with frequency 6\n",
      "Merged pair ('me', 'nt_') into token 'ment_' with frequency 6\n",
      "Merged pair ('par', 'a_') into token 'para_' with frequency 6\n"
     ]
    }
   ],
   "source": [
    "# Apply BPE\n",
    "final_vocab, final_corpus = byte_pair_encoding(corpus, vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Vocabulary: {'rha_', 'pee', 'honay_', 'scroll_', 'asar_', 'kapray_', 'you', 'movie_', 'nei_', 'fa', 'mera_', 'haa', 'd', 'tyaar_', 'no', 'karte_', 'chale_', 'sha', 'ma_', 'gi_', 'baatein_', 'sir_', '8', 'clas', 'lay_', '230_', 'par_', 'soya_', 'l', 'pohu', 'han', 'namaz_', 'jis_', 'keh_', 'kha_', 'hua_', 'compu', 'sho', 'kyun_', 'weekend_', 'kend_', 'hai_', 'ss_', 'sama', 'chla_', 'fri', 'kal_', 'chaye_', 'phone_', 'pa_', 'h', 'to', 'comp', 'een_', 'os', 'spe', 'ish_', 'apne_', 'guzar_', 'thay_', '15_', 'b_', 'hoo', 'nally_', 'instagram_', 'ba_', 'pa', 'uth_', 'na', 'lun', 'offi', 'net', 'pass_', 'khaa', 'pani_', 'har_', 'aa_', 'ho_', 'bre', 'ki_', 'maz', 'me', 'vi', 'ee', 'mila_', 'paratha_', 'saaf_', 'su', 'gym_', 'tha_', 'thaa_', '4', 'tay_', 'nee', 'hal', 'ts_', 'li', 'atte', 'ap', 'le', 'bj', 'pi', 'gh', 'mil_', 'thori_', 'muj', 'nahaya_', 'hamne_', 'jis', 'apna_', 'mj', 'ra', 'shuru_', 'ki', 'ine_', 'thy_', 'din_', 'aar_', 'dekha_', 'taqreeban_', 'soo', '12_', 'apnay_', 'jum', 'ni', 'st', 'shup_', 'zyada_', 'huwi_', 'se_', 'khai', 'bajay_', 'laptop_', 'ay_', 'ira', 'sogaya_', 'yaad_', 'chee', 'aam_', 'bohot_', 'uskay_', 'liye_', 'pahar_', 'ne_', 'au', 'ja', 'late_', 'maghrib_', 'wapas_', 'ami_', 'pehle_', 'gy', 'zy', 'kisi_', 'e_', 'ke_', 'ra_', 'ste', 'gayi_', 'ment_', 'ga_', 'boh', 'li_', 'or_', 'subha_', 'ban', 'us', 'am_', 'nascon_', 'ab_', 'z_', 'dekh_', 'fy', 'assig', 'agle_', 'kyunki_', 'mai_', 'te_', 'ghan', 'jab_', 'dair_', 'drop_', 'bana_', 'py_', 'nashta_', 'ia_', 'ck_', 'un', 'to_', 'koshish_', 'vide', 'sab', 'r', 'ary_', 'jana_', 'roo', 'ky', 'movi', 'acha_', 'chalay_', 'wali_', 'feel_', 'ad_', 'wal', 'ada_', 'quiz_', 'dinn', 'ree', 'thodi_', 'ec', 'si_', 'tk_', 'deer_', 'de_', 'ac', 'mama_', 'halka_', 'hoon_', 'pe', 'jummah_', 'ud', 'ce_', '730_', 'kiya_', 'ning_', 'iya_', 'pas_', 'attend_', 'dost', 'ghar_', 'br', 'la_', 'kash', 'wo_', 'the_', 'mobi', 'ti_', 'hot_', 'tra', 'free_', 'walon_', 'baith_', 'maa', 'ke', 'zar_', 'bahir_', 'magh', 'book_', 'i_', 'khatam_', 'magar_', 'ter_', 'pohun', 'ru', 'ex', 'he', 'baje_', 'youtube_', 'kaa', 'hue_', 'al', 'ko', 'qui', 'anda_', 'we', 'sirf_', 'thaka', 'para_', 'b', 'hon_', 'baba_', 'hui_', 'ag', 'apni_', 'lec', 'saath_', 'apny_', 'gaay_', 'meri_', 'mas', 'ri_', 'ci', 'wana_', 'cial_', 'wee', 'taq', 'ham', 'id_', 'khu', 'relax_', 'hum', 'er_', 'sig', 'bad_', 'use_', 'q', 'no_', 'sone_', 'assignme', 'chali_', 'aur_', 'chan', 'wor', 'tive_', '6_', 'likh', 'maza_', 'sonay_', 'poo', 'ce', 'khelne_', 'fresh_', 't', 'tak', 'tv_', 'gaya_', 'tti_', '600_', 'mujhe_', 'il_', 'aaya_', 'aya_', 'kh', 'ann_', 'bohat_', 'z', 're_', 'hone_', 'kia_', 't_', 'jaldi_', 'lekin_', 'pis_', 'iye_', 'iy', 'c_', 'o', 'e', 'g_', 'ham_', 'ye_', 'pp', 'bas_', 'coffee_', 'nik', 'ks_', 'baat_', 'din', 'ghanta_', 'utha_', 'fee', 'gaye_', 'rou', 'class_', 'us_', 'kam', 'pho', 'fyp_', 'dee', 'unke_', 'rib_', 'tain_', 'bo', 'khanay_', 'foot', 'es_', 'mujhay_', 'kashm', 'stop_', 'is', 'phe', 'raa', 'doston_', 'lunch_', 'da', 'assignment_', 'tyaari_', 'lap', 'ka', 'fari', 'chec', 'sion_', '2', 'ay', 'tein_', 'cafe_', 'sear', 'ush_', 'uske_', 'usy_', 'araam_', 'in', 'chi_', 'm_', 'tes_', 'a', 'lectures_', 'jisme_', 'kaha_', 'hat_', '10', '515_', 'rawana_', 'tha', 'v', 'aj', 'huw', '2_', 'meine_', 'change_', 'coffe', 'kr', 'hath_', 'khuli_', 'ta_', 'me_', 'lia_', '4_', 'bu', 'chai_', 'an', 'beech_', 'games_', 'waa', 'y', 'w_', 'mu', 'shu', 'inte', 'samaan_', '1', 'net_', 'da_', 'lena_', 'jec', 'ek_', 'nlp_', '3', 'waq', 'univ', 'pu', 'ch_', '0', 'hi_', 'finally_', 'mainay_', 'la', 'di', 'khany_', 'le_', 'rahay_', 'dha_', 'dost_', 'bana', 'lag_', 'faj', 'ach', 'nah', 'waya_', 'kh_', 'search_', 'mobile_', 'lecture_', 'lly_', 'krny_', 'diya_', 'Ã©', 'ldi_', 'main_', 'kr_', 'mehma', 'nasc', 'thi_', 'bur', 'fre', 'gai_', 'iyat_', 'p_', 'po', 'ch', 'lete_', 'trip_', 'baa', 'classes_', 'waqt_', 'oon_', 'tal_', 'start_', 'nts_', 'ball_', 'gar_', 'socha_', 'ghr_', 'huwa_', 'gay_', 'break_', 'k', 'mar', 'fi', 'projec', 'tar', 'isc', 'chal', 'ban_', 'kaay_', 'be', 'tu_', 'group_', 'sab_', 'nai_', 'dekhi_', 'assignments_', 'mee', 'mat', 'wo', 'rela', 'al_', 'ture_', 'r_', 'lectu', 'lo', 'bai', 've', 'sub', 'pohan', 'naha', 'int', 'y_', 'shaam_', 'cha_', '5', 'cha', 'inst', 'kam_', '12', 'krne_', 're', 'call_', 'cla', 'ng_', 'kar_', 'phir_', 'm', 'saa', 'aake_', 'ha', 'ls_', 'pd', 'er', 'kch_', 'bah', 'gay', 'karnay_', 'khana_', 'lagi_', 'youtu', 'ai_', 'rf_', 'bi', 'j_', 'w', 'toh_', 'nahi_', 'libr', 'pi_', 'per_', 'soo_', 'bhoo', 'wapsi_', 'ha_', 'nash', 'ponch_', 'burg', 'mein_', 'ya_', 'za', 'ns_', '6', 'x', 'tara', 'wap', 'asr_', 'ty', 'ar', 'say_', 'll_', 'isha_', 'bajy_', 'hostel_', 'bd_', 'dro', 'ju', 'at', 'rhi_', 'gh_', 'pohanch_', '7_', 'sh', 'suba_', 'raat_', 'para', 'boo', 'social_', 'as', 'gu', 'kaam_', 'tion_', 'banaya_', 'kae_', 'lapto', 'mere_', 'bhe', 'nt_', 'revise_', 'lya_', 'guzara_', 'dobara_', 'liyay_', 'subah_', 'ist', 'foo', 'sto', 'rest', 'time_', 'hay_', 'iv', 'kay_', 'ayi_', '1130_', 'co', 'nhi_', 'ta', 'nikal_', 'he_', 'parh_', 'rhe_', 'sath_', 'neend_', '40_', 'res_', 'kap', 'thora_', 'so', 'st_', 'khaya_', 'set_', 'taake_', 'lawn_', 'hy_', 'fu', 'university_', 'ry_', 'fajr_', 'n_', 'ab', 'se', 'bara_', 'kashmir_', 'tou_', 'hr_', 'gae_', 'hota_', 'samaj', 'cnet_', 'ge_', 'hain_', 'mi', 'nama', 'tar_', 'd_', 'ph', 'waja', 'baj', 'be_', '7', 'gya_', 'pehli_', 'poora_', 'ffe', 'u_', 'fi_', 'g', '5_', 'h_', 'mei_', 'ers_', 'thoda_', 'hoste', 'en', 'ky_', 'de', 'aram_', 'hama', 'ein_', 'saman_', 'it', 'asa', 'media_', 'karee', 'likh_', 'uthna_', 'parhi_', 'family_', 'game_', 'karne_', 'cour', 'pehlay_', 'wa_', 'jaa', 'networ', 'fe', 'grou', 'so_', 'i', 'wahan_', 'raha_', 'kyun', 'gyi_', 'instag', 'sa_', 'sham_', 'gup_', 'am', 'aad_', 'bed_', 'un_', 'wat_', 'ni_', 'j', 'tyari_', 'ing_', 'gari_', '8_', 'khel', 'ca', 'project_', 'complete_', 'pm_', 'bus_', '0_', 'khe', 'sc', 'moo', 'universi', 'kartay_', 'ou', 'alar', 'nay_', 'dek', 'suba', 'sh_', 'uss_', 'ran_', 'mene_', 'han_', 'parh', 'mal_', 'naye_', 'aaj_', 'library_', 'plan_', 'islama', 'dho', 'wn_', 'kya_', 'is_', 'si', 'o_', 'oo', 'utha', 'du', 'koi_', 'nch_', 'mehsoos_', '11', 'pr_', 'kosh', 'ting_', '9', 'ker', 'ir_', 'tak_', 'ja_', 'alarm_', 'f', 'f_', 'ker_', 'iya', 'n', 'ar_', 'may_', 'pe_', 'ty_', 'nashtay_', 'do_', 'cu', 'ghantay_', 'th', 'u', 'peh', 'ajj_', 'univer', 'walk_', 'kei_', 'aakar_', 'maan_', 'isliye_', 'hum_', 'office_', 'uni_', 'day_', 'pic', 'main', 'wai_', 'chala_', 'shur', 'uth', 'k_', 'mily_', 'uthne_', 'meeting_', 'pro', 'der_', 'dip_', 'zu', 'baad_', 'khata', 'uthi_', 'liya_', 'on_', 'ly_', '830_', 'dinner_', 'kai_', 'nd_', 'boht_', 'chu', 'sa', 'jo', 'room_', 'karna_', 'dekh', 'ari_', 'tab', 'ne', 'ya', 'tayar_', 'te', 'mes_', 'nal_', 'bjy_', 'qar', 'iyay_', 'per', 'bad', 'nce', 'kareeb_', 'kiye_', 'cho', 'waja_', 'rest_', 'bee', 'ho', 'ad', 'uthaya_', 'laga_', 'guz', '1_', 'ma', 'dosto_', 'revi', 'pon', 'hu', 'ko_', 'parha_', '11_', 'eeb_', 'ai', 'na_', 'tas', '9_', 'aik_', 'of', 'ny_', 'tay', 'disc', 'tri', 'kaafi_', 'tho', 'caf', 'lp_', 'nme', 'lar', 'bahar_', 'lab_', 'aj_', 'jo_', 'rahi_', 'kin_', '100_', 'tyar_', 'farigh_', 's', 'scro', '20_', 'nd', 'th_', 'sat_', 'ge', '_', 'beth_', 'and_', 'ba', 'en_', 'pdc_', 'ro', 'ri', 'c', 'tv', 'ka_', 'kafi_', 'lene_', 'di_', 'dia_', 'ti', 'aye_', 'phr_', 'hoti_', 'isla', 'karke_', 'isi_', 'jumma_', 'mo', 'a_', 'check_', 'football_', 'it_', 'l_', 'meh', 'wa', 'par', 'tayari_', 'ara_', 'tor_', 'deci', '30_', 'or', 'pata_', 'ray_', 'far', 'aa', 'aor_', 'reeban_', 'ak_', 'maine_', 'naa', 'p', 'sy_', 'x_', 'bhi_', 'dono_', 'sai_', 'pla', 'bhai_', 'cou', 'kha', 'mah_', 'islamabad_', 'qu', 'abhi_', 'wapis_', 'hogaya_', '3_', 'beh', 'aari_', 'kuch_', 'do', 'waha_', 's_', 'com', 'tiy', 'chal_', 'ee_', 'ga', 'lah_', 'ram_', 'star', 'soos_', '10_', 'mil', 'kar', 'research_', 'wajah_', '00_', 'tiv', 'khane_', 'classe', 'doos', 'ku', 'in_', 'tu'}\n",
      "\n",
      "Final Corpus Sample: [['subha_'], ['5_'], ['bj', 'he', 'y_'], ['uthna_'], ['per', 'ha_'], ['trip_'], ['thaa_'], ['jaldi_'], ['jaldi_'], ['re', 'ad', 'y_'], ['hua_'], ['aur_'], ['0', '5', '40_'], ['ghar_'], ['sa', 'ay_'], ['nikal_'], ['gaay_'], ['0', '6', '15_'], ['bus_'], ['chal_']]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Vocabulary:\", final_vocab)\n",
    "print(\"\\nFinal Corpus Sample:\", final_corpus[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocab = sorted(final_vocab)\n",
    "\n",
    "vocab_ids = {}  \n",
    "i = 1  \n",
    "\n",
    "for token in sorted_vocab:  # Iterate over sorted_vocabalary \n",
    "    vocab_ids[token] = i  # Assign index to token and then increment\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary with IDs: {'0': 1, '00_': 2, '0_': 3, '1': 4, '10': 5, '100_': 6, '10_': 7, '11': 8, '1130_': 9, '11_': 10, '12': 11, '12_': 12, '15_': 13, '1_': 14, '2': 15, '20_': 16, '230_': 17, '2_': 18, '3': 19, '30_': 20, '3_': 21, '4': 22, '40_': 23, '4_': 24, '5': 25, '515_': 26, '5_': 27, '6': 28, '600_': 29, '6_': 30, '7': 31, '730_': 32, '7_': 33, '8': 34, '830_': 35, '8_': 36, '9': 37, '9_': 38, '_': 39, 'a': 40, 'a_': 41, 'aa': 42, 'aa_': 43, 'aad_': 44, 'aaj_': 45, 'aakar_': 46, 'aake_': 47, 'aam_': 48, 'aar_': 49, 'aari_': 50, 'aaya_': 51, 'ab': 52, 'ab_': 53, 'abhi_': 54, 'ac': 55, 'ach': 56, 'acha_': 57, 'ad': 58, 'ad_': 59, 'ada_': 60, 'ag': 61, 'agle_': 62, 'ai': 63, 'ai_': 64, 'aik_': 65, 'aj': 66, 'aj_': 67, 'ajj_': 68, 'ak_': 69, 'al': 70, 'al_': 71, 'alar': 72, 'alarm_': 73, 'am': 74, 'am_': 75, 'ami_': 76, 'an': 77, 'and_': 78, 'anda_': 79, 'ann_': 80, 'aor_': 81, 'ap': 82, 'apna_': 83, 'apnay_': 84, 'apne_': 85, 'apni_': 86, 'apny_': 87, 'ar': 88, 'ar_': 89, 'ara_': 90, 'araam_': 91, 'aram_': 92, 'ari_': 93, 'ary_': 94, 'as': 95, 'asa': 96, 'asar_': 97, 'asr_': 98, 'assig': 99, 'assignme': 100, 'assignment_': 101, 'assignments_': 102, 'at': 103, 'atte': 104, 'attend_': 105, 'au': 106, 'aur_': 107, 'ay': 108, 'ay_': 109, 'aya_': 110, 'aye_': 111, 'ayi_': 112, 'b': 113, 'b_': 114, 'ba': 115, 'ba_': 116, 'baa': 117, 'baad_': 118, 'baat_': 119, 'baatein_': 120, 'baba_': 121, 'bad': 122, 'bad_': 123, 'bah': 124, 'bahar_': 125, 'bahir_': 126, 'bai': 127, 'baith_': 128, 'baj': 129, 'bajay_': 130, 'baje_': 131, 'bajy_': 132, 'ball_': 133, 'ban': 134, 'ban_': 135, 'bana': 136, 'bana_': 137, 'banaya_': 138, 'bara_': 139, 'bas_': 140, 'bd_': 141, 'be': 142, 'be_': 143, 'bed_': 144, 'bee': 145, 'beech_': 146, 'beh': 147, 'beth_': 148, 'bhai_': 149, 'bhe': 150, 'bhi_': 151, 'bhoo': 152, 'bi': 153, 'bj': 154, 'bjy_': 155, 'bo': 156, 'boh': 157, 'bohat_': 158, 'bohot_': 159, 'boht_': 160, 'boo': 161, 'book_': 162, 'br': 163, 'bre': 164, 'break_': 165, 'bu': 166, 'bur': 167, 'burg': 168, 'bus_': 169, 'c': 170, 'c_': 171, 'ca': 172, 'caf': 173, 'cafe_': 174, 'call_': 175, 'ce': 176, 'ce_': 177, 'ch': 178, 'ch_': 179, 'cha': 180, 'cha_': 181, 'chai_': 182, 'chal': 183, 'chal_': 184, 'chala_': 185, 'chalay_': 186, 'chale_': 187, 'chali_': 188, 'chan': 189, 'change_': 190, 'chaye_': 191, 'chec': 192, 'check_': 193, 'chee': 194, 'chi_': 195, 'chla_': 196, 'cho': 197, 'chu': 198, 'ci': 199, 'cial_': 200, 'ck_': 201, 'cla': 202, 'clas': 203, 'class_': 204, 'classe': 205, 'classes_': 206, 'cnet_': 207, 'co': 208, 'coffe': 209, 'coffee_': 210, 'com': 211, 'comp': 212, 'complete_': 213, 'compu': 214, 'cou': 215, 'cour': 216, 'cu': 217, 'd': 218, 'd_': 219, 'da': 220, 'da_': 221, 'dair_': 222, 'day_': 223, 'de': 224, 'de_': 225, 'deci': 226, 'dee': 227, 'deer_': 228, 'dek': 229, 'dekh': 230, 'dekh_': 231, 'dekha_': 232, 'dekhi_': 233, 'der_': 234, 'dha_': 235, 'dho': 236, 'di': 237, 'di_': 238, 'dia_': 239, 'din': 240, 'din_': 241, 'dinn': 242, 'dinner_': 243, 'dip_': 244, 'disc': 245, 'diya_': 246, 'do': 247, 'do_': 248, 'dobara_': 249, 'dono_': 250, 'doos': 251, 'dost': 252, 'dost_': 253, 'dosto_': 254, 'doston_': 255, 'dro': 256, 'drop_': 257, 'du': 258, 'e': 259, 'e_': 260, 'ec': 261, 'ee': 262, 'ee_': 263, 'eeb_': 264, 'een_': 265, 'ein_': 266, 'ek_': 267, 'en': 268, 'en_': 269, 'er': 270, 'er_': 271, 'ers_': 272, 'es_': 273, 'ex': 274, 'f': 275, 'f_': 276, 'fa': 277, 'faj': 278, 'fajr_': 279, 'family_': 280, 'far': 281, 'fari': 282, 'farigh_': 283, 'fe': 284, 'fee': 285, 'feel_': 286, 'ffe': 287, 'fi': 288, 'fi_': 289, 'finally_': 290, 'foo': 291, 'foot': 292, 'football_': 293, 'fre': 294, 'free_': 295, 'fresh_': 296, 'fri': 297, 'fu': 298, 'fy': 299, 'fyp_': 300, 'g': 301, 'g_': 302, 'ga': 303, 'ga_': 304, 'gaay_': 305, 'gae_': 306, 'gai_': 307, 'game_': 308, 'games_': 309, 'gar_': 310, 'gari_': 311, 'gay': 312, 'gay_': 313, 'gaya_': 314, 'gaye_': 315, 'gayi_': 316, 'ge': 317, 'ge_': 318, 'gh': 319, 'gh_': 320, 'ghan': 321, 'ghanta_': 322, 'ghantay_': 323, 'ghar_': 324, 'ghr_': 325, 'gi_': 326, 'grou': 327, 'group_': 328, 'gu': 329, 'gup_': 330, 'guz': 331, 'guzar_': 332, 'guzara_': 333, 'gy': 334, 'gya_': 335, 'gyi_': 336, 'gym_': 337, 'h': 338, 'h_': 339, 'ha': 340, 'ha_': 341, 'haa': 342, 'hai_': 343, 'hain_': 344, 'hal': 345, 'halka_': 346, 'ham': 347, 'ham_': 348, 'hama': 349, 'hamne_': 350, 'han': 351, 'han_': 352, 'har_': 353, 'hat_': 354, 'hath_': 355, 'hay_': 356, 'he': 357, 'he_': 358, 'hi_': 359, 'ho': 360, 'ho_': 361, 'hogaya_': 362, 'hon_': 363, 'honay_': 364, 'hone_': 365, 'hoo': 366, 'hoon_': 367, 'hoste': 368, 'hostel_': 369, 'hot_': 370, 'hota_': 371, 'hoti_': 372, 'hr_': 373, 'hu': 374, 'hua_': 375, 'hue_': 376, 'hui_': 377, 'hum': 378, 'hum_': 379, 'huw': 380, 'huwa_': 381, 'huwi_': 382, 'hy_': 383, 'i': 384, 'i_': 385, 'ia_': 386, 'id_': 387, 'il_': 388, 'in': 389, 'in_': 390, 'ine_': 391, 'ing_': 392, 'inst': 393, 'instag': 394, 'instagram_': 395, 'int': 396, 'inte': 397, 'ir_': 398, 'ira': 399, 'is': 400, 'is_': 401, 'isc': 402, 'ish_': 403, 'isha_': 404, 'isi_': 405, 'isla': 406, 'islama': 407, 'islamabad_': 408, 'isliye_': 409, 'ist': 410, 'it': 411, 'it_': 412, 'iv': 413, 'iy': 414, 'iya': 415, 'iya_': 416, 'iyat_': 417, 'iyay_': 418, 'iye_': 419, 'j': 420, 'j_': 421, 'ja': 422, 'ja_': 423, 'jaa': 424, 'jab_': 425, 'jaldi_': 426, 'jana_': 427, 'jec': 428, 'jis': 429, 'jis_': 430, 'jisme_': 431, 'jo': 432, 'jo_': 433, 'ju': 434, 'jum': 435, 'jumma_': 436, 'jummah_': 437, 'k': 438, 'k_': 439, 'ka': 440, 'ka_': 441, 'kaa': 442, 'kaafi_': 443, 'kaam_': 444, 'kaay_': 445, 'kae_': 446, 'kafi_': 447, 'kaha_': 448, 'kai_': 449, 'kal_': 450, 'kam': 451, 'kam_': 452, 'kap': 453, 'kapray_': 454, 'kar': 455, 'kar_': 456, 'karee': 457, 'kareeb_': 458, 'karke_': 459, 'karna_': 460, 'karnay_': 461, 'karne_': 462, 'kartay_': 463, 'karte_': 464, 'kash': 465, 'kashm': 466, 'kashmir_': 467, 'kay_': 468, 'kch_': 469, 'ke': 470, 'ke_': 471, 'keh_': 472, 'kei_': 473, 'kend_': 474, 'ker': 475, 'ker_': 476, 'kh': 477, 'kh_': 478, 'kha': 479, 'kha_': 480, 'khaa': 481, 'khai': 482, 'khana_': 483, 'khanay_': 484, 'khane_': 485, 'khany_': 486, 'khata': 487, 'khatam_': 488, 'khaya_': 489, 'khe': 490, 'khel': 491, 'khelne_': 492, 'khu': 493, 'khuli_': 494, 'ki': 495, 'ki_': 496, 'kia_': 497, 'kin_': 498, 'kisi_': 499, 'kiya_': 500, 'kiye_': 501, 'ko': 502, 'ko_': 503, 'koi_': 504, 'kosh': 505, 'koshish_': 506, 'kr': 507, 'kr_': 508, 'krne_': 509, 'krny_': 510, 'ks_': 511, 'ku': 512, 'kuch_': 513, 'ky': 514, 'ky_': 515, 'kya_': 516, 'kyun': 517, 'kyun_': 518, 'kyunki_': 519, 'l': 520, 'l_': 521, 'la': 522, 'la_': 523, 'lab_': 524, 'lag_': 525, 'laga_': 526, 'lagi_': 527, 'lah_': 528, 'lap': 529, 'lapto': 530, 'laptop_': 531, 'lar': 532, 'late_': 533, 'lawn_': 534, 'lay_': 535, 'ldi_': 536, 'le': 537, 'le_': 538, 'lec': 539, 'lectu': 540, 'lecture_': 541, 'lectures_': 542, 'lekin_': 543, 'lena_': 544, 'lene_': 545, 'lete_': 546, 'li': 547, 'li_': 548, 'lia_': 549, 'libr': 550, 'library_': 551, 'likh': 552, 'likh_': 553, 'liya_': 554, 'liyay_': 555, 'liye_': 556, 'll_': 557, 'lly_': 558, 'lo': 559, 'lp_': 560, 'ls_': 561, 'lun': 562, 'lunch_': 563, 'ly_': 564, 'lya_': 565, 'm': 566, 'm_': 567, 'ma': 568, 'ma_': 569, 'maa': 570, 'maan_': 571, 'magar_': 572, 'magh': 573, 'maghrib_': 574, 'mah_': 575, 'mai_': 576, 'main': 577, 'main_': 578, 'mainay_': 579, 'maine_': 580, 'mal_': 581, 'mama_': 582, 'mar': 583, 'mas': 584, 'mat': 585, 'may_': 586, 'maz': 587, 'maza_': 588, 'me': 589, 'me_': 590, 'media_': 591, 'mee': 592, 'meeting_': 593, 'meh': 594, 'mehma': 595, 'mehsoos_': 596, 'mei_': 597, 'mein_': 598, 'meine_': 599, 'mene_': 600, 'ment_': 601, 'mera_': 602, 'mere_': 603, 'meri_': 604, 'mes_': 605, 'mi': 606, 'mil': 607, 'mil_': 608, 'mila_': 609, 'mily_': 610, 'mj': 611, 'mo': 612, 'mobi': 613, 'mobile_': 614, 'moo': 615, 'movi': 616, 'movie_': 617, 'mu': 618, 'muj': 619, 'mujhay_': 620, 'mujhe_': 621, 'n': 622, 'n_': 623, 'na': 624, 'na_': 625, 'naa': 626, 'nah': 627, 'naha': 628, 'nahaya_': 629, 'nahi_': 630, 'nai_': 631, 'nal_': 632, 'nally_': 633, 'nama': 634, 'namaz_': 635, 'nasc': 636, 'nascon_': 637, 'nash': 638, 'nashta_': 639, 'nashtay_': 640, 'nay_': 641, 'naye_': 642, 'nce': 643, 'nch_': 644, 'nd': 645, 'nd_': 646, 'ne': 647, 'ne_': 648, 'nee': 649, 'neend_': 650, 'nei_': 651, 'net': 652, 'net_': 653, 'networ': 654, 'ng_': 655, 'nhi_': 656, 'ni': 657, 'ni_': 658, 'nik': 659, 'nikal_': 660, 'ning_': 661, 'nlp_': 662, 'nme': 663, 'no': 664, 'no_': 665, 'ns_': 666, 'nt_': 667, 'nts_': 668, 'ny_': 669, 'o': 670, 'o_': 671, 'of': 672, 'offi': 673, 'office_': 674, 'on_': 675, 'oo': 676, 'oon_': 677, 'or': 678, 'or_': 679, 'os': 680, 'ou': 681, 'p': 682, 'p_': 683, 'pa': 684, 'pa_': 685, 'pahar_': 686, 'pani_': 687, 'par': 688, 'par_': 689, 'para': 690, 'para_': 691, 'paratha_': 692, 'parh': 693, 'parh_': 694, 'parha_': 695, 'parhi_': 696, 'pas_': 697, 'pass_': 698, 'pata_': 699, 'pd': 700, 'pdc_': 701, 'pe': 702, 'pe_': 703, 'pee': 704, 'peh': 705, 'pehlay_': 706, 'pehle_': 707, 'pehli_': 708, 'per': 709, 'per_': 710, 'ph': 711, 'phe': 712, 'phir_': 713, 'pho': 714, 'phone_': 715, 'phr_': 716, 'pi': 717, 'pi_': 718, 'pic': 719, 'pis_': 720, 'pla': 721, 'plan_': 722, 'pm_': 723, 'po': 724, 'pohan': 725, 'pohanch_': 726, 'pohu': 727, 'pohun': 728, 'pon': 729, 'ponch_': 730, 'poo': 731, 'poora_': 732, 'pp': 733, 'pr_': 734, 'pro': 735, 'projec': 736, 'project_': 737, 'pu': 738, 'py_': 739, 'q': 740, 'qar': 741, 'qu': 742, 'qui': 743, 'quiz_': 744, 'r': 745, 'r_': 746, 'ra': 747, 'ra_': 748, 'raa': 749, 'raat_': 750, 'raha_': 751, 'rahay_': 752, 'rahi_': 753, 'ram_': 754, 'ran_': 755, 'rawana_': 756, 'ray_': 757, 're': 758, 're_': 759, 'ree': 760, 'reeban_': 761, 'rela': 762, 'relax_': 763, 'res_': 764, 'research_': 765, 'rest': 766, 'rest_': 767, 'revi': 768, 'revise_': 769, 'rf_': 770, 'rha_': 771, 'rhe_': 772, 'rhi_': 773, 'ri': 774, 'ri_': 775, 'rib_': 776, 'ro': 777, 'roo': 778, 'room_': 779, 'rou': 780, 'ru': 781, 'ry_': 782, 's': 783, 's_': 784, 'sa': 785, 'sa_': 786, 'saa': 787, 'saaf_': 788, 'saath_': 789, 'sab': 790, 'sab_': 791, 'sai_': 792, 'sama': 793, 'samaan_': 794, 'samaj': 795, 'saman_': 796, 'sat_': 797, 'sath_': 798, 'say_': 799, 'sc': 800, 'scro': 801, 'scroll_': 802, 'se': 803, 'se_': 804, 'sear': 805, 'search_': 806, 'set_': 807, 'sh': 808, 'sh_': 809, 'sha': 810, 'shaam_': 811, 'sham_': 812, 'sho': 813, 'shu': 814, 'shup_': 815, 'shur': 816, 'shuru_': 817, 'si': 818, 'si_': 819, 'sig': 820, 'sion_': 821, 'sir_': 822, 'sirf_': 823, 'so': 824, 'so_': 825, 'socha_': 826, 'social_': 827, 'sogaya_': 828, 'sonay_': 829, 'sone_': 830, 'soo': 831, 'soo_': 832, 'soos_': 833, 'soya_': 834, 'spe': 835, 'ss_': 836, 'st': 837, 'st_': 838, 'star': 839, 'start_': 840, 'ste': 841, 'sto': 842, 'stop_': 843, 'su': 844, 'sub': 845, 'suba': 846, 'suba_': 847, 'subah_': 848, 'subha_': 849, 'sy_': 850, 't': 851, 't_': 852, 'ta': 853, 'ta_': 854, 'taake_': 855, 'tab': 856, 'tain_': 857, 'tak': 858, 'tak_': 859, 'tal_': 860, 'taq': 861, 'taqreeban_': 862, 'tar': 863, 'tar_': 864, 'tara': 865, 'tas': 866, 'tay': 867, 'tay_': 868, 'tayar_': 869, 'tayari_': 870, 'te': 871, 'te_': 872, 'tein_': 873, 'ter_': 874, 'tes_': 875, 'th': 876, 'th_': 877, 'tha': 878, 'tha_': 879, 'thaa_': 880, 'thaka': 881, 'thay_': 882, 'the_': 883, 'thi_': 884, 'tho': 885, 'thoda_': 886, 'thodi_': 887, 'thora_': 888, 'thori_': 889, 'thy_': 890, 'ti': 891, 'ti_': 892, 'time_': 893, 'ting_': 894, 'tion_': 895, 'tiv': 896, 'tive_': 897, 'tiy': 898, 'tk_': 899, 'to': 900, 'to_': 901, 'toh_': 902, 'tor_': 903, 'tou_': 904, 'tra': 905, 'tri': 906, 'trip_': 907, 'ts_': 908, 'tti_': 909, 'tu': 910, 'tu_': 911, 'ture_': 912, 'tv': 913, 'tv_': 914, 'ty': 915, 'ty_': 916, 'tyaar_': 917, 'tyaari_': 918, 'tyar_': 919, 'tyari_': 920, 'u': 921, 'u_': 922, 'ud': 923, 'un': 924, 'un_': 925, 'uni_': 926, 'univ': 927, 'univer': 928, 'universi': 929, 'university_': 930, 'unke_': 931, 'us': 932, 'us_': 933, 'use_': 934, 'ush_': 935, 'uskay_': 936, 'uske_': 937, 'uss_': 938, 'usy_': 939, 'uth': 940, 'uth_': 941, 'utha': 942, 'utha_': 943, 'uthaya_': 944, 'uthi_': 945, 'uthna_': 946, 'uthne_': 947, 'v': 948, 've': 949, 'vi': 950, 'vide': 951, 'w': 952, 'w_': 953, 'wa': 954, 'wa_': 955, 'waa': 956, 'waha_': 957, 'wahan_': 958, 'wai_': 959, 'waja': 960, 'waja_': 961, 'wajah_': 962, 'wal': 963, 'wali_': 964, 'walk_': 965, 'walon_': 966, 'wana_': 967, 'wap': 968, 'wapas_': 969, 'wapis_': 970, 'wapsi_': 971, 'waq': 972, 'waqt_': 973, 'wat_': 974, 'waya_': 975, 'we': 976, 'wee': 977, 'weekend_': 978, 'wn_': 979, 'wo': 980, 'wo_': 981, 'wor': 982, 'x': 983, 'x_': 984, 'y': 985, 'y_': 986, 'ya': 987, 'ya_': 988, 'yaad_': 989, 'ye_': 990, 'you': 991, 'youtu': 992, 'youtube_': 993, 'z': 994, 'z_': 995, 'za': 996, 'zar_': 997, 'zu': 998, 'zy': 999, 'zyada_': 1000, 'Ã©': 1001}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVocabulary with IDs:\", vocab_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"Assignment_Dataset\"  \n",
    "test_list = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):  \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "            content = file.read()\n",
    "            test_list.append(content)  \n",
    "test_string = \" \".join(test_list) # convert to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r\"^\\d+\\.\\s*\", \"\", text, flags=re.MULTILINE) \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip() \n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_text = preprocess_text(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aj me subah 6 bage utha aur mene hath mun dhoya aj university late jana tha to bas hath mun dho ke me wapis bister me let gaya mere ik dost ki tabiat bhi bohat dinoun se kharab thi to subah pehle uth ke us ka hal waghaira pata kiya us ke baad jo homework university se mila tha mene who beth ke kiya or us ke baad thori der social media istemal kiya us ke baad me university gaya or wahan pe onestop ja ke apna naya student id card ka form diya us ke baad mene apni sab classes attend kin university se chutti ke baad me apne dostoun ke sath garioun ke showrooms me gaya kyunke ik dost ko gari leni thi us ke baad ham ne wapsi pe ik jaga se khana khaya or wapis flat agae us ke baad mene apni raat ki dawaian lin or bas homework jo rehta tha complete kar ke sogaya 1 aj me subah 9 bage utha or mene ghanta dost se baat ki us ke baad mene nashta kiya or university jane kelia tyar hoa university me pehli class 1 bage thi to bas sari classes attend kin sab classes attend kar ke flat wapis agea or apne liye khana banaya khana bana ke mene dost or ammi se thori baat ki us ke baad mene apne quizzes tyar kiye quizzes tyar karne ke baad thori der phone use kiya or dost se baat kar ke kuch hi der me sogaya 1 aj me subah 6 30 pe utha or kapre istari kiye us ke baad me university gaya 11 30 tak lectures attend kar ke me cs lawn me agaya or dost ke sath time spend kiya dopehr me ade pe gaya chakwal wapis ane kelia sham me apne ghar phuncha fresh hoke khana khaya us ke baad mene thori der drama dekha or dost se baat ki us ke baad mene game kheli raat me mene homework jama karwaya or kuch hi der me sogaya 1 aj me subah 7 bage utha or mene dost se baat ki us ke baad mene nashta kiya nashta karne ke baad mene thori der youtube dekha us ke baad dost se baat hoi or ammi ke sath chashma banwane gaya us ke baad mene khana khaya or dada ko hospital leke gaya sham me raat ko wapis ane ke baad khana khaya dost se baat ki or homework kiya us ke baad kuch hi der me sogaya 1 aj me subah 8 bage utha nashta kiya us ke baad mene apni assignment shuru ki or sham to woh beth ke ki beech me mene khana khaya or namazen ada kin shaam me me baal katwane gaya wapis ake raat ka khana khaya thori der dost se baat ki us ke baad kuch der game mene game kheli kyunke kaal subah wapis university jana tha to packing ki or kuch der me homework kar ke sogaya 1 aj me subah 5 bage utha kyunke mene islamabad ana tha uth ke namaz parhi or bus se islamabad aya ake mene university me classes attend kin us ke baad me dostoun ke sath khana khane gaya wapis ake mene namaz parhi us ke baad mene dost se baat ki or assignment ki us ke baad kuch der me sogaya 1 aj wednesday tha meri university se chuti thi din ka aghaz koi khas acha nai hoa tha mera mood bohat kharab tha uth ke kyunke chuti thi to flat me hi reh ke nashta kiya or kuch der phone pe baad dost se flat me mere pas kuch karne ko hota nai ha to me bohat bor hoa poora din dopehr me mene dawa khai khane ke sath or bas zuhr or asar ki namaz parh ke leta raha bed pe maghrib ke time maghrib ki namaz ada kar ke mene raat ka khana or dawa khai aj ka din kuch khas acha nai tha mere liye me apne ap ko bohat down feel kar raha tha or aisa koi bhi nai tha jis se me baat karta us ke baad mene apna nlp ka task likha or submit kiya us ke baad mene ishaa ki namaz ada ki or apna bed sahi kiya or kuch der me hi me sogaya 1 aj me subah 7 bage utha or uth ke mene sab se pehle mun waghaira dhoya or dost se baat ki us ke baad me university jane kelia tyar ho aj hamari class 1 bage thi par me 8 30 university chala gaya kyunke flat me bor hota houn me wahan ja ke kuch der me cafe me betha or us ke baad lab me chala gaya wahan ja ke mene ann ka dost ke sath ik topic revise kiya or dip ka quiz tyar kiya us ke baad ham lrc chale gae jahan par mene class mates ko quiz ki tyari karwai us ke baad ham cafe gae wahan se kuch khane kelia leke cs ground beth gae us ke baad mene student card banwana tha to onestop se woh banwaya or class me chale gae teeno classes attend karne ke baad me wapis flat agea or aj ki nlp ki diary likhi us ke baad mene khana khaya dawai li or kuch der me dost se baat kar ke sogaya 1 aj me subah jaldi utha kyunke 8 30 class thi me jaldi se dost ki nai gari me university me gaya dono classes jaldi se attend kar ke ham free hogae phir thori der cs lawn me betha dost ke sath us ke baad me cafe gaya or samosa chaat khai us ke baad me faizabad gaya or chakwal wali gari me betha kyunke aj wapis ana tha sara safar gane or sunte we or sote we guzara shaam ko wapis phuncha or behn ke sath qabristan or ik do jaga or gaya wapis ake khana khaya or game kheli thori si us ke baad mene apna homework kiya or kuch hi der me sogaya 1 aj meri university se chuti thi kyunke saturday tha to me thora der se utha us ke baad me neeche gaya ammi se mila or beth ke nashta kiya us ke baad mene thori si game kheli or meri nani amma log agae neeche ja ke un se mila or phir mene university ki fees jama karwai fees jama karwa ke phir se game khelne lag gaya or beech me namaz bhi parhi us ke baad me let gaya bister me or phone use karte karte kuch der kelia sogaya uth ke mene asar parhi or ammi ke phone pe mobile protector lagwane kelia chala gaya wapis ake mene jaldi se wuzoo kiya or maghrib ki namaz ada ki or thori der game kheli us ke baad mene khana khaya apna homework kiya or ishaa parh ke kuch der phone istemal karne ke baad sogaya 1 aj sunday tha me 9 bage utha or mun hath dhoe us ke baad ammi ne kaha ke behn ke sath ja ke aj bahir se halwa poori le ao nashte kelia to woh leke aya us ke baad mene thori der game kheli or phir gari saaf ki aj kyunke wapis islamabad ana tha to dopehr me nahaya naha ke mene packing ki or us ke baad mene khana khaya khana kha ke thori der baad me ghar se wapis kelia niqal gaya 3 ghanta baad me islamabad phuncha or apne flat agea flat ake mene apne liye khane kelia sandwich banaya khana kha ke mene homework kiya apna or thori der let gaya us ke baad mene din ki sari namazen ada kin  dawaian lin or kuch hi der me sogaya 1 aj me subah 7 bage utha or fresh hoke university gaya university me mene apne lectures attend kiye or us ke baad dost se treat lene gaya treat lene ke baad ham kuch dost ice cream khane gae or phir dost ke hi flat chale gae wahan par ham ne thori si game kheli or maghrib ke time sab apne apne ghar chale gae wapis ake mene thora sa rest kiya kyunke kaafi thak gaya tha rest karne ke baad mene apna homework kiya university ka us ke baad mene kaza namazen ada kin poore din ki us ke baad khana kha ke me dobara se let gaya or kuch hi der me phone istemal karte karte sogaya 1 aj me subah 9 bage utha or uth ke mun hath dhoya us ke baad me university gaya or wahan wrap khaya sari classes attend karne ke baad ham cs lawn me chale gae aj hamare ik dost ki birthday thi to cake khaya cake kha ke wapis flat agae or change kiya us ke baad dost ke sath game kheli thori or phir khana khane bahir chale gae khana kha ke ham ne ice cream khai us ke baad wapis flat ae or mene apna homework kiya home work kar ke me sone kelia let gaya or kuch hi der me sogaya 1 aj me subah 9 bage utha or kyunke university se chuti thi to bahir nashta karne gaya nashta kar ke wapis aya or nahaya naha kar mene chai banai jise pee kar me bister me let gaya thori der mene phone use kiya dost se baat ki or instagram chalaya dopehr me  me fruit leke aya or woh khaya us ke baad mene thori der aram kiya aram karne ke baad me utha raat ka khana khaya khana kha ke mene homework kiya or kuch hi der me  me sogaya'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Text: [67, 590, 848, 30, 115, 318, 943, 107, 600, 355, 618, 623, 236, 988, 67, 930, 533, 427, 879, 901, 140, 355, 618, 623, 236, 39, 471, 590, 970, 153, 841, 746, 590, 537, 852, 314, 603, 384, 439, 253, 496, 856, 384, 103, 39, 151, 158, 240, 681, 623, 804, 479, 747, 114, 884, 901, 848, 707, 941, 471, 933, 441, 345, 39, 954, 319, 63, 748, 699, 500, 933, 471, 118, 433, 360, 589, 982, 439, 930, 804, 609, 879, 600, 952, 361, 148, 471, 500, 679, 933, 471, 118, 889, 234, 827, 591, 410, 259, 581, 500, 933, 471, 118, 590, 930, 314, 679, 958, 703, 670, 647, 843, 423, 471, 83, 624, 988, 837, 923, 268, 852, 387, 172, 745, 219, 441, 275, 678, 567, 246, 933, 471, 118, 600, 86, 791, 206, 105, 498, 930, 804, 198, 909, 471, 118, 590, 85, 252, 681, 623, 471, 798, 303, 774, 681, 623, 471, 813, 952, 778, 566, 784, 590, 314, 517, 471, 384, 439, 253, 503, 311, 537, 658, 884, 933, 471, 118, 348, 648, 971, 703, 384, 439, 422, 304, 804, 483, 489, 679, 970, 275, 522, 852, 61, 40, 260, 933, 471, 118, 600, 86, 750, 496, 220, 954, 384, 77, 39, 547, 623, 679, 140, 360, 589, 982, 439, 433, 758, 338, 854, 879, 213, 456, 471, 828, 14, 67, 590, 848, 38, 115, 318, 943, 679, 600, 322, 253, 804, 119, 496, 933, 471, 118, 600, 639, 500, 679, 930, 422, 648, 470, 549, 919, 360, 41, 930, 590, 708, 204, 14, 115, 318, 884, 901, 140, 785, 775, 206, 105, 498, 791, 206, 105, 456, 471, 275, 522, 852, 970, 61, 259, 41, 679, 85, 556, 483, 138, 483, 137, 471, 600, 253, 679, 74, 606, 39, 804, 889, 119, 496, 933, 471, 118, 600, 85, 743, 994, 994, 273, 919, 501, 743, 994, 994, 273, 919, 462, 471, 118, 889, 234, 715, 934, 500, 679, 253, 804, 119, 456, 471, 513, 359, 234, 590, 828, 14, 67, 590, 848, 30, 20, 703, 943, 679, 453, 759, 410, 93, 501, 933, 471, 118, 590, 930, 314, 10, 20, 859, 542, 105, 456, 471, 590, 170, 784, 534, 590, 61, 110, 679, 253, 471, 798, 893, 835, 646, 500, 247, 705, 746, 590, 58, 260, 703, 314, 180, 438, 963, 39, 970, 77, 260, 470, 549, 812, 590, 85, 324, 711, 924, 181, 296, 360, 471, 483, 489, 933, 471, 118, 600, 889, 234, 218, 747, 569, 232, 679, 253, 804, 119, 496, 933, 471, 118, 600, 308, 491, 385, 750, 590, 600, 360, 589, 982, 439, 422, 569, 455, 975, 679, 513, 359, 234, 590, 828, 14, 67, 590, 848, 33, 115, 318, 943, 679, 600, 253, 804, 119, 496, 933, 471, 118, 600, 639, 500, 639, 462, 471, 118, 600, 889, 234, 993, 232, 933, 471, 118, 253, 804, 119, 360, 385, 679, 74, 606, 39, 471, 798, 180, 808, 569, 134, 954, 648, 314, 933, 471, 118, 600, 483, 489, 679, 220, 221, 503, 360, 783, 717, 860, 537, 471, 314, 812, 590, 750, 503, 970, 77, 260, 471, 118, 483, 489, 253, 804, 119, 496, 679, 360, 589, 982, 439, 500, 933, 471, 118, 513, 359, 234, 590, 828, 14, 67, 590, 848, 36, 115, 318, 943, 639, 500, 933, 471, 118, 600, 86, 101, 817, 496, 679, 812, 901, 980, 339, 148, 471, 496, 146, 590, 600, 483, 489, 679, 634, 994, 269, 60, 498, 811, 590, 590, 117, 521, 440, 851, 954, 648, 314, 970, 40, 471, 750, 441, 483, 489, 889, 234, 253, 804, 119, 496, 933, 471, 118, 513, 234, 308, 600, 308, 491, 385, 517, 471, 442, 521, 848, 970, 930, 427, 879, 901, 684, 170, 495, 655, 496, 679, 513, 234, 590, 360, 589, 982, 439, 456, 471, 828, 14, 67, 590, 848, 27, 115, 318, 943, 517, 471, 600, 408, 77, 41, 879, 941, 471, 635, 696, 679, 169, 804, 408, 110, 40, 471, 600, 930, 590, 206, 105, 498, 933, 471, 118, 590, 252, 681, 623, 471, 798, 483, 485, 314, 970, 40, 471, 600, 635, 696, 933, 471, 118, 600, 253, 804, 119, 496, 679, 101, 496, 933, 471, 118, 513, 234, 590, 828, 14, 67, 976, 218, 647, 783, 223, 879, 604, 930, 804, 198, 892, 884, 241, 441, 61, 340, 995, 504, 479, 784, 57, 631, 360, 41, 879, 602, 615, 219, 158, 479, 747, 114, 879, 941, 471, 517, 471, 198, 892, 884, 901, 275, 522, 852, 590, 359, 758, 339, 471, 639, 500, 679, 513, 234, 715, 703, 118, 253, 804, 275, 522, 852, 590, 603, 697, 513, 462, 503, 371, 631, 341, 901, 590, 158, 156, 746, 360, 41, 732, 241, 247, 705, 746, 590, 600, 220, 955, 482, 39, 485, 471, 798, 679, 140, 998, 373, 679, 97, 496, 635, 694, 471, 537, 854, 751, 144, 703, 574, 471, 893, 574, 496, 635, 60, 456, 471, 600, 750, 441, 483, 679, 220, 955, 482, 39, 67, 441, 241, 513, 479, 784, 57, 631, 879, 603, 556, 590, 85, 82, 39, 503, 158, 247, 979, 286, 456, 751, 879, 679, 63, 786, 504, 151, 631, 879, 430, 804, 590, 119, 455, 854, 933, 471, 118, 600, 83, 662, 441, 866, 439, 552, 41, 679, 845, 606, 852, 500, 933, 471, 118, 600, 400, 342, 39, 496, 635, 60, 496, 679, 83, 144, 785, 359, 500, 679, 513, 234, 590, 359, 590, 828, 14, 67, 590, 848, 33, 115, 318, 943, 679, 941, 471, 600, 791, 804, 707, 618, 623, 954, 319, 63, 748, 236, 988, 679, 253, 804, 119, 496, 933, 471, 118, 590, 930, 422, 648, 470, 549, 919, 361, 67, 349, 775, 204, 14, 115, 318, 884, 689, 590, 36, 20, 930, 185, 314, 517, 471, 275, 522, 852, 590, 156, 746, 371, 360, 925, 590, 958, 423, 471, 513, 234, 590, 174, 590, 142, 879, 679, 933, 471, 118, 524, 590, 185, 314, 958, 423, 471, 600, 80, 441, 253, 471, 798, 384, 439, 900, 719, 39, 769, 500, 679, 244, 441, 744, 919, 500, 933, 471, 118, 348, 520, 745, 171, 187, 306, 422, 352, 689, 600, 204, 585, 273, 503, 744, 496, 920, 455, 959, 933, 471, 118, 348, 174, 306, 958, 804, 513, 485, 470, 549, 537, 471, 170, 784, 327, 646, 148, 306, 933, 471, 118, 600, 837, 923, 268, 852, 172, 745, 219, 134, 967, 879, 901, 670, 647, 843, 804, 980, 339, 134, 975, 679, 204, 590, 187, 306, 871, 268, 671, 206, 105, 462, 471, 118, 590, 970, 275, 522, 852, 61, 259, 41, 679, 67, 496, 662, 496, 237, 94, 552, 385, 933, 471, 118, 600, 483, 489, 220, 959, 548, 679, 513, 234, 590, 253, 804, 119, 456, 471, 828, 14, 67, 590, 848, 426, 943, 517, 471, 36, 20, 204, 884, 590, 426, 804, 253, 496, 631, 311, 590, 930, 590, 314, 250, 206, 426, 804, 105, 456, 471, 348, 295, 360, 306, 713, 889, 234, 170, 784, 534, 590, 142, 879, 253, 471, 798, 933, 471, 118, 590, 174, 314, 679, 785, 612, 786, 180, 103, 39, 482, 39, 933, 471, 118, 590, 277, 384, 996, 123, 314, 679, 180, 438, 963, 39, 964, 311, 590, 142, 879, 517, 471, 67, 970, 77, 41, 879, 785, 748, 785, 281, 39, 303, 648, 679, 844, 622, 872, 976, 39, 679, 824, 872, 976, 39, 333, 811, 503, 970, 711, 924, 181, 679, 147, 623, 471, 798, 740, 52, 774, 837, 77, 39, 679, 384, 439, 248, 422, 304, 679, 314, 970, 40, 471, 483, 489, 679, 308, 491, 385, 889, 819, 933, 471, 118, 600, 83, 360, 589, 982, 439, 500, 679, 513, 359, 234, 590, 828, 14, 67, 604, 930, 804, 198, 892, 884, 517, 471, 785, 910, 745, 223, 879, 901, 590, 888, 234, 804, 943, 933, 471, 118, 590, 649, 178, 260, 314, 74, 606, 39, 804, 609, 679, 148, 471, 639, 500, 933, 471, 118, 600, 889, 819, 308, 491, 385, 679, 604, 624, 658, 74, 569, 559, 302, 61, 40, 260, 649, 178, 260, 423, 471, 925, 804, 609, 679, 713, 600, 930, 496, 285, 784, 422, 569, 455, 959, 285, 784, 422, 569, 455, 955, 471, 713, 804, 308, 492, 525, 314, 679, 146, 590, 635, 151, 696, 933, 471, 118, 590, 537, 852, 314, 153, 841, 746, 590, 679, 715, 934, 464, 464, 513, 234, 470, 549, 828, 941, 471, 600, 97, 696, 679, 74, 606, 39, 471, 715, 703, 614, 735, 871, 170, 903, 522, 301, 954, 648, 470, 549, 185, 314, 970, 40, 471, 600, 426, 804, 952, 921, 994, 676, 39, 500, 679, 574, 496, 635, 60, 496, 679, 889, 234, 308, 491, 385, 933, 471, 118, 600, 483, 489, 83, 360, 589, 982, 439, 500, 679, 400, 342, 39, 694, 471, 513, 234, 715, 410, 259, 581, 462, 471, 118, 828, 14, 67, 844, 645, 109, 879, 590, 38, 115, 318, 943, 679, 618, 623, 355, 236, 260, 933, 471, 118, 74, 606, 39, 648, 448, 471, 147, 623, 471, 798, 423, 471, 67, 126, 804, 345, 955, 731, 775, 538, 40, 671, 638, 872, 470, 549, 901, 980, 339, 537, 471, 110, 933, 471, 118, 600, 889, 234, 308, 491, 385, 679, 713, 311, 788, 496, 67, 517, 471, 970, 408, 77, 41, 879, 901, 247, 705, 746, 590, 629, 628, 39, 471, 600, 684, 170, 495, 655, 496, 679, 933, 471, 118, 600, 483, 489, 483, 480, 471, 889, 234, 118, 590, 324, 804, 970, 470, 549, 657, 740, 71, 314, 21, 322, 118, 590, 408, 711, 924, 181, 679, 85, 275, 522, 852, 61, 259, 41, 275, 522, 852, 40, 471, 600, 85, 556, 485, 470, 549, 785, 645, 952, 384, 179, 138, 483, 480, 471, 600, 360, 589, 982, 439, 500, 83, 679, 889, 234, 537, 852, 314, 933, 471, 118, 600, 241, 496, 785, 775, 634, 994, 269, 60, 498, 39, 220, 954, 384, 77, 39, 547, 623, 679, 513, 359, 234, 590, 828, 14, 67, 590, 848, 33, 115, 318, 943, 679, 296, 360, 471, 930, 314, 930, 590, 600, 85, 542, 105, 501, 679, 933, 471, 118, 253, 804, 851, 758, 103, 39, 545, 314, 851, 758, 103, 39, 545, 471, 118, 348, 513, 253, 384, 177, 170, 758, 75, 485, 306, 679, 713, 253, 471, 359, 275, 522, 852, 187, 306, 958, 689, 348, 648, 889, 819, 308, 491, 385, 679, 574, 471, 893, 791, 85, 85, 324, 187, 306, 970, 40, 471, 600, 888, 786, 767, 500, 517, 471, 443, 878, 439, 314, 879, 767, 462, 471, 118, 600, 83, 360, 589, 982, 439, 500, 930, 441, 933, 471, 118, 600, 440, 996, 39, 634, 994, 269, 60, 498, 731, 759, 241, 496, 933, 471, 118, 483, 480, 471, 590, 249, 804, 537, 852, 314, 679, 513, 359, 234, 590, 715, 410, 259, 581, 464, 464, 828, 14, 67, 590, 848, 38, 115, 318, 943, 679, 941, 471, 618, 623, 355, 236, 988, 933, 471, 118, 590, 930, 314, 679, 958, 952, 747, 683, 489, 785, 775, 206, 105, 462, 471, 118, 348, 170, 784, 534, 590, 187, 306, 67, 349, 759, 384, 439, 253, 496, 153, 745, 876, 223, 884, 901, 172, 471, 489, 172, 471, 480, 471, 970, 275, 522, 852, 61, 40, 260, 679, 190, 500, 933, 471, 118, 253, 471, 798, 308, 491, 385, 889, 679, 713, 483, 485, 126, 187, 306, 483, 480, 471, 348, 648, 384, 177, 170, 758, 75, 482, 39, 933, 471, 118, 970, 275, 522, 852, 40, 260, 679, 600, 83, 360, 589, 982, 439, 500, 360, 590, 982, 439, 456, 471, 590, 830, 470, 549, 537, 852, 314, 679, 513, 359, 234, 590, 828, 14, 67, 590, 848, 38, 115, 318, 943, 679, 517, 471, 930, 804, 198, 892, 884, 901, 126, 639, 462, 314, 639, 456, 471, 970, 110, 679, 629, 628, 39, 456, 600, 182, 136, 385, 429, 260, 704, 39, 456, 590, 153, 841, 746, 590, 537, 852, 314, 889, 234, 600, 715, 934, 500, 253, 804, 119, 496, 679, 395, 183, 110, 247, 705, 746, 590, 39, 590, 275, 781, 412, 537, 471, 110, 679, 980, 339, 489, 933, 471, 118, 600, 889, 234, 92, 500, 92, 462, 471, 118, 590, 943, 750, 441, 483, 489, 483, 480, 471, 600, 360, 589, 982, 439, 500, 679, 513, 359, 234, 590, 39, 590, 824, 312, 40]\n",
      "Decoded Text: aj me subah 6 bage utha aur mene hath mun dhoya aj university late jana tha to bas hath mun dho ke me wapis bister me let gaya mere ik dost ki tabiat bhi bohat dinoun se kharab thi to subah pehle uth ke us ka hal waghaira pata kiya us ke baad jo homework university se mila tha mene who beth ke kiya or us ke baad thori der social media istemal kiya us ke baad me university gaya or wahan pe onestop ja ke apna naya student id card ka form diya us ke baad mene apni sab classes attend kin university se chutti ke baad me apne dostoun ke sath garioun ke showrooms me gaya kyunke ik dost ko gari leni thi us ke baad ham ne wapsi pe ik jaga se khana khaya or wapis flat agae us ke baad mene apni raat ki dawaian lin or bas homework jo rehta tha complete kar ke sogaya 1 aj me subah 9 bage utha or mene ghanta dost se baat ki us ke baad mene nashta kiya or university jane kelia tyar hoa university me pehli class 1 bage thi to bas sari classes attend kin sab classes attend kar ke flat wapis agea or apne liye khana banaya khana bana ke mene dost or ammi se thori baat ki us ke baad mene apne quizzes tyar kiye quizzes tyar karne ke baad thori der phone use kiya or dost se baat kar ke kuch hi der me sogaya 1 aj me subah 6 30 pe utha or kapre istari kiye us ke baad me university gaya 11 30 tak lectures attend kar ke me cs lawn me agaya or dost ke sath time spend kiya dopehr me ade pe gaya chakwal wapis ane kelia sham me apne ghar phuncha fresh hoke khana khaya us ke baad mene thori der drama dekha or dost se baat ki us ke baad mene game kheli raat me mene homework jama karwaya or kuch hi der me sogaya 1 aj me subah 7 bage utha or mene dost se baat ki us ke baad mene nashta kiya nashta karne ke baad mene thori der youtube dekha us ke baad dost se baat hoi or ammi ke sath chashma banwane gaya us ke baad mene khana khaya or dada ko hospital leke gaya sham me raat ko wapis ane ke baad khana khaya dost se baat ki or homework kiya us ke baad kuch hi der me sogaya 1 aj me subah 8 bage utha nashta kiya us ke baad mene apni assignment shuru ki or sham to woh beth ke ki beech me mene khana khaya or namazen ada kin shaam me me baal katwane gaya wapis ake raat ka khana khaya thori der dost se baat ki us ke baad kuch der game mene game kheli kyunke kaal subah wapis university jana tha to packing ki or kuch der me homework kar ke sogaya 1 aj me subah 5 bage utha kyunke mene islamabad ana tha uth ke namaz parhi or bus se islamabad aya ake mene university me classes attend kin us ke baad me dostoun ke sath khana khane gaya wapis ake mene namaz parhi us ke baad mene dost se baat ki or assignment ki us ke baad kuch der me sogaya 1 aj wednesday tha meri university se chuti thi din ka aghaz koi khas acha nai hoa tha mera mood bohat kharab tha uth ke kyunke chuti thi to flat me hi reh ke nashta kiya or kuch der phone pe baad dost se flat me mere pas kuch karne ko hota nai ha to me bohat bor hoa poora din dopehr me mene dawa khai khane ke sath or bas zuhr or asar ki namaz parh ke leta raha bed pe maghrib ke time maghrib ki namaz ada kar ke mene raat ka khana or dawa khai aj ka din kuch khas acha nai tha mere liye me apne ap ko bohat down feel kar raha tha or aisa koi bhi nai tha jis se me baat karta us ke baad mene apna nlp ka task likha or submit kiya us ke baad mene ishaa ki namaz ada ki or apna bed sahi kiya or kuch der me hi me sogaya 1 aj me subah 7 bage utha or uth ke mene sab se pehle mun waghaira dhoya or dost se baat ki us ke baad me university jane kelia tyar ho aj hamari class 1 bage thi par me 8 30 university chala gaya kyunke flat me bor hota houn me wahan ja ke kuch der me cafe me betha or us ke baad lab me chala gaya wahan ja ke mene ann ka dost ke sath ik topic revise kiya or dip ka quiz tyar kiya us ke baad ham lrc chale gae jahan par mene class mates ko quiz ki tyari karwai us ke baad ham cafe gae wahan se kuch khane kelia leke cs ground beth gae us ke baad mene student card banwana tha to onestop se woh banwaya or class me chale gae teeno classes attend karne ke baad me wapis flat agea or aj ki nlp ki diary likhi us ke baad mene khana khaya dawai li or kuch der me dost se baat kar ke sogaya 1 aj me subah jaldi utha kyunke 8 30 class thi me jaldi se dost ki nai gari me university me gaya dono classes jaldi se attend kar ke ham free hogae phir thori der cs lawn me betha dost ke sath us ke baad me cafe gaya or samosa chaat khai us ke baad me faizabad gaya or chakwal wali gari me betha kyunke aj wapis ana tha sara safar gane or sunte we or sote we guzara shaam ko wapis phuncha or behn ke sath qabristan or ik do jaga or gaya wapis ake khana khaya or game kheli thori si us ke baad mene apna homework kiya or kuch hi der me sogaya 1 aj meri university se chuti thi kyunke saturday tha to me thora der se utha us ke baad me neeche gaya ammi se mila or beth ke nashta kiya us ke baad mene thori si game kheli or meri nani amma log agae neeche ja ke un se mila or phir mene university ki fees jama karwai fees jama karwa ke phir se game khelne lag gaya or beech me namaz bhi parhi us ke baad me let gaya bister me or phone use karte karte kuch der kelia sogaya uth ke mene asar parhi or ammi ke phone pe mobile protector lagwane kelia chala gaya wapis ake mene jaldi se wuzoo kiya or maghrib ki namaz ada ki or thori der game kheli us ke baad mene khana khaya apna homework kiya or ishaa parh ke kuch der phone istemal karne ke baad sogaya 1 aj sunday tha me 9 bage utha or mun hath dhoe us ke baad ammi ne kaha ke behn ke sath ja ke aj bahir se halwa poori le ao nashte kelia to woh leke aya us ke baad mene thori der game kheli or phir gari saaf ki aj kyunke wapis islamabad ana tha to dopehr me nahaya naha ke mene packing ki or us ke baad mene khana khaya khana kha ke thori der baad me ghar se wapis kelia niqal gaya 3 ghanta baad me islamabad phuncha or apne flat agea flat ake mene apne liye khane kelia sandwich banaya khana kha ke mene homework kiya apna or thori der let gaya us ke baad mene din ki sari namazen ada kin  dawaian lin or kuch hi der me sogaya 1 aj me subah 7 bage utha or fresh hoke university gaya university me mene apne lectures attend kiye or us ke baad dost se treat lene gaya treat lene ke baad ham kuch dost ice cream khane gae or phir dost ke hi flat chale gae wahan par ham ne thori si game kheli or maghrib ke time sab apne apne ghar chale gae wapis ake mene thora sa rest kiya kyunke kaafi thak gaya tha rest karne ke baad mene apna homework kiya university ka us ke baad mene kaza namazen ada kin poore din ki us ke baad khana kha ke me dobara se let gaya or kuch hi der me phone istemal karte karte sogaya 1 aj me subah 9 bage utha or uth ke mun hath dhoya us ke baad me university gaya or wahan wrap khaya sari classes attend karne ke baad ham cs lawn me chale gae aj hamare ik dost ki birthday thi to cake khaya cake kha ke wapis flat agae or change kiya us ke baad dost ke sath game kheli thori or phir khana khane bahir chale gae khana kha ke ham ne ice cream khai us ke baad wapis flat ae or mene apna homework kiya home work kar ke me sone kelia let gaya or kuch hi der me sogaya 1 aj me subah 9 bage utha or kyunke university se chuti thi to bahir nashta karne gaya nashta kar ke wapis aya or nahaya naha kar mene chai banai jise pee kar me bister me let gaya thori der mene phone use kiya dost se baat ki or instagram chalaya dopehr me  me fruit leke aya or woh khaya us ke baad mene thori der aram kiya aram karne ke baad me utha raat ka khana khaya khana kha ke mene homework kiya or kuch hi der me  me sogaya\n"
     ]
    }
   ],
   "source": [
    "encoded_text = encode(processed_test_text, vocab_ids)\n",
    "print(\"Encoded Text:\", encoded_text)\n",
    "\n",
    "decoded_text = decode(encoded_text, vocab_ids)  # Pass vocab_ids here\n",
    "print(\"Decoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and decode example with emojis and invalid characters\n",
    "# test_text = \"mera dost bht acha ha hia ð ð¥ ð @#!\"\n",
    "# encoded_text = encode(test_text, final_vocab)\n",
    "# print(\"Encoded Text:\", encoded_text)\n",
    "\n",
    "# decoded_text = decode(encoded_text)\n",
    "# print(\"Decoded Text:\", decoded_text)\n",
    "\n",
    "# #Assert that the decoded text matches the original text (ignoring <UNK>)\n",
    "# assert decoded_text == test_text.replace(\"<UNK>\", \"\"), \"Decoded text does not match the original text!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluate its performance based on vocabulary reduction and OOV word handling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary size havent been reduced because we are adding new pairs inside vocabulary and are not removing previous characters which are getting merged as per course instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
